{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e9afb02-c70f-48c7-9581-9bd458ac1070",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def load_data_from_files(data_dir):\n",
    "    all_data = []\n",
    "    for filename in os.listdir(data_dir):\n",
    "        if filename.endswith('.csv'):\n",
    "            # Extract metadata from filename\n",
    "            collection_id, step_info, _ = filename.split('_', 2)\n",
    "            step_number = ''.join(filter(str.isdigit, step_info))\n",
    "            foot = 'R' if 'R' in step_info else 'L'\n",
    "            filepath = os.path.join(data_dir, filename)\n",
    "            df = pd.read_csv(filepath)\n",
    "            df['collection_id'] = collection_id\n",
    "            df['step_number'] = int(step_number)\n",
    "            df['foot'] = foot\n",
    "            df['filename'] = filename  # Keep track of the file\n",
    "            all_data.append(df)\n",
    "    return pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "data_dir = 'csv_output'  # Replace with your directory\n",
    "data = load_data_from_files(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94500e7d-bb7d-4e81-a727-d38834260beb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>gyroscope_x</th>\n",
       "      <th>gyroscope_y</th>\n",
       "      <th>gyroscope_z</th>\n",
       "      <th>accelerometer_x</th>\n",
       "      <th>accelerometer_y</th>\n",
       "      <th>accelerometer_z</th>\n",
       "      <th>event</th>\n",
       "      <th>collection_id</th>\n",
       "      <th>step_number</th>\n",
       "      <th>foot</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-06-14 10:55:50.108</td>\n",
       "      <td>-176.225</td>\n",
       "      <td>-420.175</td>\n",
       "      <td>-26.740</td>\n",
       "      <td>5.992396</td>\n",
       "      <td>-0.633180</td>\n",
       "      <td>-5.532456</td>\n",
       "      <td>1</td>\n",
       "      <td>BsxSnoTsRktvZsac1xw4</td>\n",
       "      <td>10</td>\n",
       "      <td>L</td>\n",
       "      <td>BsxSnoTsRktvZsac1xw4_10 L_sensor_data_with_eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-06-14 10:55:50.113</td>\n",
       "      <td>-191.625</td>\n",
       "      <td>-247.345</td>\n",
       "      <td>-23.870</td>\n",
       "      <td>-1.918572</td>\n",
       "      <td>0.501420</td>\n",
       "      <td>1.586976</td>\n",
       "      <td>1</td>\n",
       "      <td>BsxSnoTsRktvZsac1xw4</td>\n",
       "      <td>10</td>\n",
       "      <td>L</td>\n",
       "      <td>BsxSnoTsRktvZsac1xw4_10 L_sensor_data_with_eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-06-14 10:55:50.118</td>\n",
       "      <td>-183.610</td>\n",
       "      <td>-305.025</td>\n",
       "      <td>-4.900</td>\n",
       "      <td>0.643428</td>\n",
       "      <td>-0.413824</td>\n",
       "      <td>-1.687748</td>\n",
       "      <td>1</td>\n",
       "      <td>BsxSnoTsRktvZsac1xw4</td>\n",
       "      <td>10</td>\n",
       "      <td>L</td>\n",
       "      <td>BsxSnoTsRktvZsac1xw4_10 L_sensor_data_with_eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-06-14 10:55:50.122</td>\n",
       "      <td>-169.610</td>\n",
       "      <td>-285.460</td>\n",
       "      <td>-3.150</td>\n",
       "      <td>-0.540460</td>\n",
       "      <td>0.331108</td>\n",
       "      <td>-2.173064</td>\n",
       "      <td>0</td>\n",
       "      <td>BsxSnoTsRktvZsac1xw4</td>\n",
       "      <td>10</td>\n",
       "      <td>L</td>\n",
       "      <td>BsxSnoTsRktvZsac1xw4_10 L_sensor_data_with_eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-06-14 10:55:50.127</td>\n",
       "      <td>-176.610</td>\n",
       "      <td>-286.510</td>\n",
       "      <td>-7.035</td>\n",
       "      <td>-0.383568</td>\n",
       "      <td>0.077592</td>\n",
       "      <td>-1.338828</td>\n",
       "      <td>0</td>\n",
       "      <td>BsxSnoTsRktvZsac1xw4</td>\n",
       "      <td>10</td>\n",
       "      <td>L</td>\n",
       "      <td>BsxSnoTsRktvZsac1xw4_10 L_sensor_data_with_eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508441</th>\n",
       "      <td>2024-06-14 09:32:38.284</td>\n",
       "      <td>46.445</td>\n",
       "      <td>-48.265</td>\n",
       "      <td>-48.825</td>\n",
       "      <td>4.747508</td>\n",
       "      <td>1.361032</td>\n",
       "      <td>-1.638948</td>\n",
       "      <td>0</td>\n",
       "      <td>hiG83ssX2DUOVgSmNQWr</td>\n",
       "      <td>12</td>\n",
       "      <td>L</td>\n",
       "      <td>hiG83ssX2DUOVgSmNQWr_12 L_sensor_data_with_eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508442</th>\n",
       "      <td>2024-06-14 09:32:38.289</td>\n",
       "      <td>13.265</td>\n",
       "      <td>-87.465</td>\n",
       "      <td>-67.375</td>\n",
       "      <td>4.352228</td>\n",
       "      <td>1.148752</td>\n",
       "      <td>-1.632848</td>\n",
       "      <td>0</td>\n",
       "      <td>hiG83ssX2DUOVgSmNQWr</td>\n",
       "      <td>12</td>\n",
       "      <td>L</td>\n",
       "      <td>hiG83ssX2DUOVgSmNQWr_12 L_sensor_data_with_eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508443</th>\n",
       "      <td>2024-06-14 09:32:38.294</td>\n",
       "      <td>-12.320</td>\n",
       "      <td>-121.380</td>\n",
       "      <td>-84.035</td>\n",
       "      <td>3.929864</td>\n",
       "      <td>0.920856</td>\n",
       "      <td>-1.625772</td>\n",
       "      <td>0</td>\n",
       "      <td>hiG83ssX2DUOVgSmNQWr</td>\n",
       "      <td>12</td>\n",
       "      <td>L</td>\n",
       "      <td>hiG83ssX2DUOVgSmNQWr_12 L_sensor_data_with_eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508444</th>\n",
       "      <td>2024-06-14 09:32:38.299</td>\n",
       "      <td>-26.005</td>\n",
       "      <td>-146.440</td>\n",
       "      <td>-98.210</td>\n",
       "      <td>3.452356</td>\n",
       "      <td>0.619272</td>\n",
       "      <td>-1.646512</td>\n",
       "      <td>1</td>\n",
       "      <td>hiG83ssX2DUOVgSmNQWr</td>\n",
       "      <td>12</td>\n",
       "      <td>L</td>\n",
       "      <td>hiG83ssX2DUOVgSmNQWr_12 L_sensor_data_with_eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508445</th>\n",
       "      <td>2024-06-14 09:32:38.304</td>\n",
       "      <td>-44.870</td>\n",
       "      <td>-175.980</td>\n",
       "      <td>-105.770</td>\n",
       "      <td>2.526620</td>\n",
       "      <td>-0.989420</td>\n",
       "      <td>-1.821704</td>\n",
       "      <td>1</td>\n",
       "      <td>hiG83ssX2DUOVgSmNQWr</td>\n",
       "      <td>12</td>\n",
       "      <td>L</td>\n",
       "      <td>hiG83ssX2DUOVgSmNQWr_12 L_sensor_data_with_eve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>508446 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           time  gyroscope_x  gyroscope_y  gyroscope_z  \\\n",
       "0       2024-06-14 10:55:50.108     -176.225     -420.175      -26.740   \n",
       "1       2024-06-14 10:55:50.113     -191.625     -247.345      -23.870   \n",
       "2       2024-06-14 10:55:50.118     -183.610     -305.025       -4.900   \n",
       "3       2024-06-14 10:55:50.122     -169.610     -285.460       -3.150   \n",
       "4       2024-06-14 10:55:50.127     -176.610     -286.510       -7.035   \n",
       "...                         ...          ...          ...          ...   \n",
       "508441  2024-06-14 09:32:38.284       46.445      -48.265      -48.825   \n",
       "508442  2024-06-14 09:32:38.289       13.265      -87.465      -67.375   \n",
       "508443  2024-06-14 09:32:38.294      -12.320     -121.380      -84.035   \n",
       "508444  2024-06-14 09:32:38.299      -26.005     -146.440      -98.210   \n",
       "508445  2024-06-14 09:32:38.304      -44.870     -175.980     -105.770   \n",
       "\n",
       "        accelerometer_x  accelerometer_y  accelerometer_z  event  \\\n",
       "0              5.992396        -0.633180        -5.532456      1   \n",
       "1             -1.918572         0.501420         1.586976      1   \n",
       "2              0.643428        -0.413824        -1.687748      1   \n",
       "3             -0.540460         0.331108        -2.173064      0   \n",
       "4             -0.383568         0.077592        -1.338828      0   \n",
       "...                 ...              ...              ...    ...   \n",
       "508441         4.747508         1.361032        -1.638948      0   \n",
       "508442         4.352228         1.148752        -1.632848      0   \n",
       "508443         3.929864         0.920856        -1.625772      0   \n",
       "508444         3.452356         0.619272        -1.646512      1   \n",
       "508445         2.526620        -0.989420        -1.821704      1   \n",
       "\n",
       "               collection_id  step_number foot  \\\n",
       "0       BsxSnoTsRktvZsac1xw4           10    L   \n",
       "1       BsxSnoTsRktvZsac1xw4           10    L   \n",
       "2       BsxSnoTsRktvZsac1xw4           10    L   \n",
       "3       BsxSnoTsRktvZsac1xw4           10    L   \n",
       "4       BsxSnoTsRktvZsac1xw4           10    L   \n",
       "...                      ...          ...  ...   \n",
       "508441  hiG83ssX2DUOVgSmNQWr           12    L   \n",
       "508442  hiG83ssX2DUOVgSmNQWr           12    L   \n",
       "508443  hiG83ssX2DUOVgSmNQWr           12    L   \n",
       "508444  hiG83ssX2DUOVgSmNQWr           12    L   \n",
       "508445  hiG83ssX2DUOVgSmNQWr           12    L   \n",
       "\n",
       "                                                 filename  \n",
       "0       BsxSnoTsRktvZsac1xw4_10 L_sensor_data_with_eve...  \n",
       "1       BsxSnoTsRktvZsac1xw4_10 L_sensor_data_with_eve...  \n",
       "2       BsxSnoTsRktvZsac1xw4_10 L_sensor_data_with_eve...  \n",
       "3       BsxSnoTsRktvZsac1xw4_10 L_sensor_data_with_eve...  \n",
       "4       BsxSnoTsRktvZsac1xw4_10 L_sensor_data_with_eve...  \n",
       "...                                                   ...  \n",
       "508441  hiG83ssX2DUOVgSmNQWr_12 L_sensor_data_with_eve...  \n",
       "508442  hiG83ssX2DUOVgSmNQWr_12 L_sensor_data_with_eve...  \n",
       "508443  hiG83ssX2DUOVgSmNQWr_12 L_sensor_data_with_eve...  \n",
       "508444  hiG83ssX2DUOVgSmNQWr_12 L_sensor_data_with_eve...  \n",
       "508445  hiG83ssX2DUOVgSmNQWr_12 L_sensor_data_with_eve...  \n",
       "\n",
       "[508446 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11d941c9-0b8b-480d-a3bb-3dfd0e90366d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "\n",
    "def preprocess_data(data):\n",
    "    # Define features and target\n",
    "    features = ['gyroscope_x', 'gyroscope_y', 'gyroscope_z',\n",
    "                'accelerometer_x', 'accelerometer_y', 'accelerometer_z']\n",
    "    target = 'event'\n",
    "\n",
    "    # Drop rows with missing values\n",
    "    data = data.dropna(subset=features + [target])\n",
    "\n",
    "    # Normalize features\n",
    "    scaler = MinMaxScaler()\n",
    "    data[features] = scaler.fit_transform(data[features])\n",
    "\n",
    "    # Encode target labels\n",
    "    label_encoder = LabelEncoder()\n",
    "    data[target] = label_encoder.fit_transform(data[target])\n",
    "\n",
    "    return data, label_encoder\n",
    "\n",
    "data, label_encoder = preprocess_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "981aac76-7ec4-45b4-abd7-8b1a3fd0731f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SensorDataset(Dataset):\n",
    "    def __init__(self, data, features, target, sequence_length):\n",
    "        self.features = features\n",
    "        self.target = target\n",
    "        self.sequence_length = sequence_length\n",
    "        self.sequences = []\n",
    "        self.labels = []\n",
    "\n",
    "        grouped = data.groupby('filename')\n",
    "\n",
    "        for _, group in grouped:\n",
    "            group = group.reset_index(drop=True)\n",
    "            group_length = len(group)\n",
    "            if group_length >= sequence_length:\n",
    "                # Generate sequences using a sliding window\n",
    "                for i in range(group_length - sequence_length + 1):\n",
    "                    seq = group.iloc[i:i+sequence_length]\n",
    "                    self.sequences.append(seq[self.features].values)\n",
    "                    # Use the event at the last time point as the label\n",
    "                    self.labels.append(seq[self.target].values[-1])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = self.sequences[idx]\n",
    "        y = self.labels[idx]\n",
    "        return torch.tensor(X, dtype=torch.float32), torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "# Parameters\n",
    "features = ['gyroscope_x', 'gyroscope_y', 'gyroscope_z',\n",
    "            'accelerometer_x', 'accelerometer_y', 'accelerometer_z']\n",
    "target = 'event'\n",
    "sequence_length = 50  # hyperparameter to be tuned\n",
    "\n",
    "dataset = SensorDataset(data, features, target, sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe0aacd2-1b0a-47e8-aaaf-d671fac21f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# 70 - 15 - 15 split\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = int(0.15 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "# Split dataset\n",
    "train_dataset, val_dataset, test_dataset = random_split(\n",
    "    dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# Create DataLoaders\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd6a4e09-34ca-466f-9f3c-aa73aba0fdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, num_classes, dropout=0.5):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers,\n",
    "                            batch_first=True, dropout=dropout)\n",
    "\n",
    "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, seq_length, input_dim)\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(x.device)\n",
    "\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])  # Take output from the last time step\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a8c83ee-58b5-4db7-a5c1-a5065a22d591",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "input_dim = len(features)\n",
    "hidden_dim = 64\n",
    "num_layers = 2\n",
    "num_classes = len(label_encoder.classes_)\n",
    "learning_rate = 0.001\n",
    "num_epochs = 20\n",
    "\n",
    "model = LSTMClassifier(input_dim, hidden_dim, num_layers, num_classes).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f0ea3a7-0194-422f-a4f5-4def5ad238d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for X_batch, y_batch in loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * X_batch.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += y_batch.size(0)\n",
    "        correct += (predicted == y_batch).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(loader.dataset)\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def validate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "\n",
    "            running_loss += loss.item() * X_batch.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += y_batch.size(0)\n",
    "            correct += (predicted == y_batch).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(loader.dataset)\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6f206122-7d73-4149-a9ac-f987d981c421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Train Loss: 0.2368, Train Acc: 0.9372, Val Loss: 0.1887, Val Acc: 0.9382\n",
      "Epoch 2/20, Train Loss: 0.1890, Train Acc: 0.9392, Val Loss: 0.1851, Val Acc: 0.9404\n",
      "Epoch 3/20, Train Loss: 0.1861, Train Acc: 0.9400, Val Loss: 0.1914, Val Acc: 0.9366\n",
      "Epoch 4/20, Train Loss: 0.1848, Train Acc: 0.9403, Val Loss: 0.1855, Val Acc: 0.9409\n",
      "Epoch 5/20, Train Loss: 0.1838, Train Acc: 0.9405, Val Loss: 0.1825, Val Acc: 0.9409\n",
      "Epoch 6/20, Train Loss: 0.1826, Train Acc: 0.9408, Val Loss: 0.1815, Val Acc: 0.9410\n",
      "Epoch 7/20, Train Loss: 0.1825, Train Acc: 0.9408, Val Loss: 0.1844, Val Acc: 0.9404\n",
      "Epoch 8/20, Train Loss: 0.1819, Train Acc: 0.9408, Val Loss: 0.1824, Val Acc: 0.9407\n",
      "Epoch 9/20, Train Loss: 0.1815, Train Acc: 0.9410, Val Loss: 0.1832, Val Acc: 0.9397\n",
      "Epoch 10/20, Train Loss: 0.1810, Train Acc: 0.9410, Val Loss: 0.1816, Val Acc: 0.9407\n",
      "Epoch 11/20, Train Loss: 0.1809, Train Acc: 0.9411, Val Loss: 0.1812, Val Acc: 0.9412\n",
      "Epoch 12/20, Train Loss: 0.1814, Train Acc: 0.9408, Val Loss: 0.1836, Val Acc: 0.9411\n",
      "Epoch 13/20, Train Loss: 0.1798, Train Acc: 0.9412, Val Loss: 0.1795, Val Acc: 0.9412\n",
      "Epoch 14/20, Train Loss: 0.1797, Train Acc: 0.9412, Val Loss: 0.1789, Val Acc: 0.9415\n",
      "Epoch 15/20, Train Loss: 0.1795, Train Acc: 0.9414, Val Loss: 0.1791, Val Acc: 0.9415\n",
      "Epoch 16/20, Train Loss: 0.1789, Train Acc: 0.9413, Val Loss: 0.1790, Val Acc: 0.9413\n",
      "Epoch 17/20, Train Loss: 0.1788, Train Acc: 0.9413, Val Loss: 0.1787, Val Acc: 0.9412\n",
      "Epoch 18/20, Train Loss: 0.1784, Train Acc: 0.9413, Val Loss: 0.1794, Val Acc: 0.9417\n",
      "Epoch 19/20, Train Loss: 0.1781, Train Acc: 0.9413, Val Loss: 0.1798, Val Acc: 0.9412\n",
      "Epoch 20/20, Train Loss: 0.1776, Train Acc: 0.9413, Val Loss: 0.1770, Val Acc: 0.9415\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss, val_acc = validate(model, val_loader, criterion, device)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, '\n",
    "          f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, '\n",
    "          f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7d2d8e-7b81-4727-ac6b-2035d962978d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1732, Test Acc: 0.9431\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = validate(model, test_loader, criterion, device)\n",
    "print(f'Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "df8864c1-d4ac-41b4-919e-d6accae6bc8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    no event       0.94      1.00      0.97     55490\n",
      " heel strike       0.76      0.52      0.61       798\n",
      "   foot flat       0.00      0.00      0.00         0\n",
      "    heel off       0.00      0.00      0.00      1386\n",
      "     toe off       0.36      0.00      0.01      1462\n",
      "\n",
      "    accuracy                           0.94     59136\n",
      "   macro avg       0.41      0.30      0.32     59136\n",
      "weighted avg       0.91      0.94      0.92     59136\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ap/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/ap/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/ap/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/ap/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/ap/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/ap/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/ap/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/ap/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/ap/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Collect predictions and true labels\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        outputs = model(X_batch)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(y_batch.cpu().numpy())\n",
    "\n",
    "# Define all possible labels\n",
    "labels = range(num_classes)  # Ensure num_classes is set correctly (should be 5)\n",
    "\n",
    "# Manually define class names\n",
    "class_names = ['no event', 'heel strike', 'foot flat', 'heel off', 'toe off']\n",
    "\n",
    "# Generate the classification report\n",
    "print(classification_report(all_labels, all_preds, labels=labels, target_names=class_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "15007905-137f-487b-ad80-7f81dba7be90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model weights saved to lstm_model.pth\n"
     ]
    }
   ],
   "source": [
    "# After training is complete\n",
    "model_save_path = 'lstm_model.pth'\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "print(f\"Model weights saved to {model_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2dcf589d-325e-444a-87e1-9b49bc41ed3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model weights loaded from lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5z/lbjsn1j53z78qzp3pp99pctc0000gn/T/ipykernel_1886/1298699598.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  loaded_model.load_state_dict(torch.load(model_load_path))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LSTMClassifier(\n",
       "  (lstm): LSTM(6, 64, num_layers=2, batch_first=True, dropout=0.5)\n",
       "  (fc): Linear(in_features=64, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the model architecture\n",
    "loaded_model = LSTMClassifier(input_dim, hidden_dim, num_layers, num_classes)\n",
    "loaded_model.to(device)\n",
    "\n",
    "# Load the saved weights\n",
    "model_load_path = 'lstm_model.pth'\n",
    "loaded_model.load_state_dict(torch.load(model_load_path))\n",
    "print(f\"Model weights loaded from {model_load_path}\")\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "loaded_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4ea9bb9-2077-4921-8f8a-ee13077c38c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Model Test Loss: 0.1732, Test Acc: 0.9431\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on the test set\n",
    "test_loss, test_acc = validate(loaded_model, test_loader, criterion, device)\n",
    "print(f'Loaded Model Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf705a52-c52a-4cc3-99e4-3ce324a235db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    no event       0.94      1.00      0.97     55490\n",
      " heel strike       0.76      0.52      0.61       798\n",
      "   foot flat       0.00      0.00      0.00         0\n",
      "    heel off       0.00      0.00      0.00      1386\n",
      "     toe off       0.36      0.00      0.01      1462\n",
      "\n",
      "    accuracy                           0.94     59136\n",
      "   macro avg       0.41      0.30      0.32     59136\n",
      "weighted avg       0.91      0.94      0.92     59136\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ap/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/ap/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/ap/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/ap/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/ap/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/ap/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/ap/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/ap/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/ap/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Collect predictions and true labels\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        outputs = loaded_model(X_batch)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(y_batch.cpu().numpy())\n",
    "\n",
    "# Define all possible labels\n",
    "labels = range(num_classes)  # Ensure num_classes is set correctly (should be 5)\n",
    "\n",
    "# Manually define class names\n",
    "class_names = ['no event', 'heel strike', 'foot flat', 'heel off', 'toe off']\n",
    "\n",
    "# Generate the classification report\n",
    "print(classification_report(all_labels, all_preds, labels=labels, target_names=class_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb44ff83-5e7c-4a92-be1c-ceec9f50043c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
