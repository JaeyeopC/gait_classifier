{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# data_dir = '/content/drive/MyDrive/csv_output_with_phases'b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../csv_output_with_phases'  # Replace with your directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scikit-learn version: 1.5.2\n",
      "XGBoost version: 2.1.3\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import xgboost\n",
    "\n",
    "# To use gridsearch from sklearn for XGBoost, Scikit-learn versino should be lower than 1.6.0\n",
    "print(f\"Scikit-learn version: {sklearn.__version__}\")\n",
    "print(f\"XGBoost version: {xgboost.__version__}\")\n",
    "\n",
    "type(sklearn.__version__)\n",
    "try:\n",
    "  if sklearn.__version__ >= \"1.6.0\":\n",
    "    raise Exception(\"sklearn version should be lower than 1.6.0\")\n",
    "except Exception as e:\n",
    "  print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data head 보여주기\n",
    "# data column 설명 추가\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def load_data_from_files(data_dir):\n",
    "    all_data = []\n",
    "    for filename in os.listdir(data_dir):\n",
    "        if filename.endswith('.csv'):\n",
    "            # Extract metadata from filename\n",
    "            collection_id, step_info, _ = filename.split('_', 2)\n",
    "            step_number = ''.join(filter(str.isdigit, step_info))\n",
    "            foot = 'R' if 'R' in step_info else 'L'\n",
    "            filepath = os.path.join(data_dir, filename)\n",
    "\n",
    "            df = pd.read_csv(filepath)\n",
    "\n",
    "            df['collection_id'] = collection_id + '_' + str(step_number) + '_' + foot\n",
    "            df['filename'] = filename  # Keep track of the file\n",
    "            df['time'] = pd.to_datetime(df['time'])  # Ensure 'time' column is in datetime format\n",
    "            df['elapsed_time'] = (df['time'] - df['time'].min()).dt.total_seconds()\n",
    "            df['gyroscope_magnitude'] = np.sqrt(df['gyroscope_x']**2 + df['gyroscope_y']**2 + df['gyroscope_z']**2)\n",
    "            df['accelerometer_magnitude'] = np.sqrt(df['accelerometer_x']**2 + df['accelerometer_y']**2 + df['accelerometer_z']**2)\n",
    "            cols = ['collection_id', 'elapsed_time', 'gyroscope_x', 'gyroscope_y',\n",
    "                    'gyroscope_z', 'accelerometer_x', 'accelerometer_y', 'accelerometer_z', 'phase', 'gyroscope_magnitude', 'accelerometer_magnitude'] # , 'foot', 'filename']\n",
    "            df = df[cols]\n",
    "            # df = df[df['phase'] != 0]\n",
    "            all_data.append(df)\n",
    "    return pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "data = load_data_from_files(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>collection_id</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>gyroscope_x</th>\n",
       "      <th>gyroscope_y</th>\n",
       "      <th>gyroscope_z</th>\n",
       "      <th>accelerometer_x</th>\n",
       "      <th>accelerometer_y</th>\n",
       "      <th>accelerometer_z</th>\n",
       "      <th>phase</th>\n",
       "      <th>gyroscope_magnitude</th>\n",
       "      <th>accelerometer_magnitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vh92aaJeQLxDazem2hN5_6_L</td>\n",
       "      <td>0.000</td>\n",
       "      <td>168.63</td>\n",
       "      <td>-158.62</td>\n",
       "      <td>-113.82</td>\n",
       "      <td>-1.026752</td>\n",
       "      <td>2.276032</td>\n",
       "      <td>-8.625400</td>\n",
       "      <td>1</td>\n",
       "      <td>257.975529</td>\n",
       "      <td>8.979536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vh92aaJeQLxDazem2hN5_6_L</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-71.89</td>\n",
       "      <td>-272.58</td>\n",
       "      <td>-129.92</td>\n",
       "      <td>-2.516616</td>\n",
       "      <td>-1.586000</td>\n",
       "      <td>-2.127680</td>\n",
       "      <td>1</td>\n",
       "      <td>310.398510</td>\n",
       "      <td>3.657291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vh92aaJeQLxDazem2hN5_6_L</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-129.85</td>\n",
       "      <td>-334.53</td>\n",
       "      <td>-114.10</td>\n",
       "      <td>-0.890112</td>\n",
       "      <td>-0.234240</td>\n",
       "      <td>0.258640</td>\n",
       "      <td>1</td>\n",
       "      <td>376.550333</td>\n",
       "      <td>0.956066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vh92aaJeQLxDazem2hN5_6_L</td>\n",
       "      <td>0.015</td>\n",
       "      <td>-206.85</td>\n",
       "      <td>-334.60</td>\n",
       "      <td>-111.30</td>\n",
       "      <td>-0.842288</td>\n",
       "      <td>0.425048</td>\n",
       "      <td>-1.624064</td>\n",
       "      <td>1</td>\n",
       "      <td>408.817530</td>\n",
       "      <td>1.878217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vh92aaJeQLxDazem2hN5_6_L</td>\n",
       "      <td>0.020</td>\n",
       "      <td>-223.65</td>\n",
       "      <td>-354.62</td>\n",
       "      <td>-105.70</td>\n",
       "      <td>0.108824</td>\n",
       "      <td>0.293288</td>\n",
       "      <td>-1.969568</td>\n",
       "      <td>1</td>\n",
       "      <td>432.373862</td>\n",
       "      <td>1.994256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              collection_id  elapsed_time  gyroscope_x  gyroscope_y  \\\n",
       "0  vh92aaJeQLxDazem2hN5_6_L         0.000       168.63      -158.62   \n",
       "1  vh92aaJeQLxDazem2hN5_6_L         0.005       -71.89      -272.58   \n",
       "2  vh92aaJeQLxDazem2hN5_6_L         0.010      -129.85      -334.53   \n",
       "3  vh92aaJeQLxDazem2hN5_6_L         0.015      -206.85      -334.60   \n",
       "4  vh92aaJeQLxDazem2hN5_6_L         0.020      -223.65      -354.62   \n",
       "\n",
       "   gyroscope_z  accelerometer_x  accelerometer_y  accelerometer_z  phase  \\\n",
       "0      -113.82        -1.026752         2.276032        -8.625400      1   \n",
       "1      -129.92        -2.516616        -1.586000        -2.127680      1   \n",
       "2      -114.10        -0.890112        -0.234240         0.258640      1   \n",
       "3      -111.30        -0.842288         0.425048        -1.624064      1   \n",
       "4      -105.70         0.108824         0.293288        -1.969568      1   \n",
       "\n",
       "   gyroscope_magnitude  accelerometer_magnitude  \n",
       "0           257.975529                 8.979536  \n",
       "1           310.398510                 3.657291  \n",
       "2           376.550333                 0.956066  \n",
       "3           408.817530                 1.878217  \n",
       "4           432.373862                 1.994256  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "\n",
    "def preprocess_data(data):\n",
    "    # Define features and target\n",
    "    features = ['gyroscope_x', 'gyroscope_y', 'gyroscope_z',\n",
    "                'accelerometer_x', 'accelerometer_y', 'accelerometer_z', 'gyroscope_magnitude', 'accelerometer_magnitude']\n",
    "    target = 'phase'\n",
    "\n",
    "    # Drop rows with missing values\n",
    "    data = data.dropna(subset=features + [target])\n",
    "\n",
    "    # Drop rows with no event\n",
    "    data = data[data[target] != 0]\n",
    "\n",
    "    # Subtract the phase by 1 : XGboost takes a value from 0 ~ (num_class-1)\n",
    "    data[target] = data[target] - 1\n",
    "\n",
    "    # Normalize features\n",
    "    scaler = MinMaxScaler()\n",
    "    data.loc[:, features] = scaler.fit_transform(data[features])\n",
    "\n",
    "    # Encode target labels\n",
    "    label_encoder = LabelEncoder()\n",
    "    data.loc[:, target] = label_encoder.fit_transform(data[target])\n",
    "\n",
    "    return data, label_encoder\n",
    "\n",
    "scaled_data, label_encoder = preprocess_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>collection_id</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>gyroscope_x</th>\n",
       "      <th>gyroscope_y</th>\n",
       "      <th>gyroscope_z</th>\n",
       "      <th>accelerometer_x</th>\n",
       "      <th>accelerometer_y</th>\n",
       "      <th>accelerometer_z</th>\n",
       "      <th>phase</th>\n",
       "      <th>gyroscope_magnitude</th>\n",
       "      <th>accelerometer_magnitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vh92aaJeQLxDazem2hN5_6_L</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.691635</td>\n",
       "      <td>0.489820</td>\n",
       "      <td>0.233674</td>\n",
       "      <td>0.414113</td>\n",
       "      <td>0.588787</td>\n",
       "      <td>0.219917</td>\n",
       "      <td>0</td>\n",
       "      <td>0.242176</td>\n",
       "      <td>0.560265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vh92aaJeQLxDazem2hN5_6_L</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.498991</td>\n",
       "      <td>0.405266</td>\n",
       "      <td>0.212696</td>\n",
       "      <td>0.335429</td>\n",
       "      <td>0.371178</td>\n",
       "      <td>0.471328</td>\n",
       "      <td>0</td>\n",
       "      <td>0.291461</td>\n",
       "      <td>0.220911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vh92aaJeQLxDazem2hN5_6_L</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.452568</td>\n",
       "      <td>0.359302</td>\n",
       "      <td>0.233309</td>\n",
       "      <td>0.421329</td>\n",
       "      <td>0.447344</td>\n",
       "      <td>0.563660</td>\n",
       "      <td>0</td>\n",
       "      <td>0.353653</td>\n",
       "      <td>0.048677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vh92aaJeQLxDazem2hN5_6_L</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.390895</td>\n",
       "      <td>0.359250</td>\n",
       "      <td>0.236957</td>\n",
       "      <td>0.423855</td>\n",
       "      <td>0.484492</td>\n",
       "      <td>0.490814</td>\n",
       "      <td>0</td>\n",
       "      <td>0.383989</td>\n",
       "      <td>0.107475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vh92aaJeQLxDazem2hN5_6_L</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.377439</td>\n",
       "      <td>0.344396</td>\n",
       "      <td>0.244254</td>\n",
       "      <td>0.474086</td>\n",
       "      <td>0.477068</td>\n",
       "      <td>0.477446</td>\n",
       "      <td>0</td>\n",
       "      <td>0.406135</td>\n",
       "      <td>0.114874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              collection_id  elapsed_time  gyroscope_x  gyroscope_y  \\\n",
       "0  vh92aaJeQLxDazem2hN5_6_L         0.000     0.691635     0.489820   \n",
       "1  vh92aaJeQLxDazem2hN5_6_L         0.005     0.498991     0.405266   \n",
       "2  vh92aaJeQLxDazem2hN5_6_L         0.010     0.452568     0.359302   \n",
       "3  vh92aaJeQLxDazem2hN5_6_L         0.015     0.390895     0.359250   \n",
       "4  vh92aaJeQLxDazem2hN5_6_L         0.020     0.377439     0.344396   \n",
       "\n",
       "   gyroscope_z  accelerometer_x  accelerometer_y  accelerometer_z  phase  \\\n",
       "0     0.233674         0.414113         0.588787         0.219917      0   \n",
       "1     0.212696         0.335429         0.371178         0.471328      0   \n",
       "2     0.233309         0.421329         0.447344         0.563660      0   \n",
       "3     0.236957         0.423855         0.484492         0.490814      0   \n",
       "4     0.244254         0.474086         0.477068         0.477446      0   \n",
       "\n",
       "   gyroscope_magnitude  accelerometer_magnitude  \n",
       "0             0.242176                 0.560265  \n",
       "1             0.291461                 0.220911  \n",
       "2             0.353653                 0.048677  \n",
       "3             0.383989                 0.107475  \n",
       "4             0.406135                 0.114874  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the lag size (ACF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import acf\n",
    "from joblib import Parallel, delayed\n",
    "import numpy as np\n",
    "\n",
    "def compute_cutoff_lag(target, nlags=50):\n",
    "    \"\"\"Compute cutoff lag for a single time series.\"\"\"\n",
    "    acf_values, confint = acf(target, alpha=0.05, nlags=nlags)\n",
    "    # confidential interval\n",
    "    lower_bound = confint[1:, 0] - acf_values[1:]\n",
    "    upper_bound = confint[1:, 1] - acf_values[1:]\n",
    "    cutoff_lag = np.where((acf_values[1:] < lower_bound) | (acf_values[1:] > upper_bound))[0]\n",
    "    if len(cutoff_lag) > 0:\n",
    "        return cutoff_lag[-1] + 1  # Adjust index to match lag\n",
    "    return 0\n",
    "\n",
    "def get_lag_size(data, nlags=50):\n",
    "    \"\"\"Compute average cutoff lag across all collection IDs.\"\"\"\n",
    "    collection_ids = data['collection_id'].unique()\n",
    "\n",
    "    # Use parallel processing for speed\n",
    "    cutoff_lags = Parallel(n_jobs=-1)(delayed(compute_cutoff_lag)(\n",
    "        data[data['collection_id'] == collection_id]['phase'], nlags\n",
    "    ) for collection_id in collection_ids)\n",
    "\n",
    "    lag_size = round(np.mean(cutoff_lags))\n",
    "    print(f'average lag_size: {lag_size}')\n",
    "    return lag_size\n",
    "\n",
    "lag_size = get_lag_size(scaled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "\n",
    "# ACF example plot \n",
    "def plot_acf_example(data):\n",
    "    random_collection_id = np.random.choice(data['collection_id'].unique(), 1, replace=False)\n",
    "    phase = data[data['collection_id'] == random_collection_id[0]]['phase']\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plot_acf(phase, lags=50)\n",
    "    plt.title(f'ACF Plot for Collection ID: {random_collection_id[0]}')\n",
    "    plt.show()\n",
    "\n",
    "plot_acf_example(scaled_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lagged Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lagged_DataSet():\n",
    "    def __init__(self, data, features, target, lag_size=30):\n",
    "        self.data = data\n",
    "        self.features = features\n",
    "        self.len_features = len(self.features)\n",
    "        self.target = target\n",
    "        self.lag_size = lag_size\n",
    "\n",
    "        self.collection_id = 0\n",
    "\n",
    "        self.X = pd.DataFrame()\n",
    "        self.y = pd.DataFrame()\n",
    "        self.collection_ids = pd.DataFrame()\n",
    "\n",
    "        for collection_id in self.data['collection_id'].unique()[:50]:\n",
    "            collection_data = self.data[self.data['collection_id'] == collection_id].sort_values(by='elapsed_time')\n",
    "            collection_data = collection_data[self.features + ['phase'] + ['collection_id']]\n",
    "            # collection_data = collection_data[self.features + ['phase']]\n",
    "            collection_length = len(collection_data)\n",
    "            if collection_length > self.lag_size:\n",
    "                lagged_features = {}\n",
    "                for j in range(self.len_features):\n",
    "                    for i in range(1, self.lag_size):\n",
    "                        lagged_features[f'{self.features[j]}_lag{i}'] = collection_data[self.features[j]].shift(i)\n",
    "                lagged_df = pd.DataFrame(lagged_features)\n",
    "                collection_data = pd.concat([collection_data, lagged_df], axis=1)\n",
    "\n",
    "            collection_data.dropna(inplace=True)\n",
    "            collection_data['collection_id'] = self.collection_id\n",
    "\n",
    "            collection_data = collection_data.drop(columns=self.features)\n",
    "            collection_data = collection_data.dropna(axis=1, how='any')\n",
    "\n",
    "            # self.X = pd.concat([self.X, collection_data.drop(columns=[self.target])], ignore_index=True)\n",
    "            self.X = pd.concat([self.X, collection_data.drop(columns=['phase', 'collection_id'])], ignore_index=True)\n",
    "            self.y = pd.concat([self.y, collection_data[[self.target]]], ignore_index=True)\n",
    "            self.collection_ids = pd.concat([self.collection_ids, collection_data[['collection_id']]], ignore_index=True)\n",
    "\n",
    "            self.collection_id += 1\n",
    "\n",
    "        self.X_df = self.X.copy()\n",
    "        self.y_df = self.y.copy()\n",
    "        self.collection_ids_df = self.collection_ids.copy()\n",
    "\n",
    "        self.X = self.X_df.values\n",
    "        self.y = self.y_df.values\n",
    "        self.collection_ids = self.collection_ids_df.values \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "features = ['gyroscope_x', 'gyroscope_y', 'gyroscope_z',\n",
    "            'accelerometer_x', 'accelerometer_y', 'accelerometer_z']\n",
    "target = 'phase'\n",
    "dataset = Lagged_DataSet(scaled_data, features, target, lag_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gyroscope_x_lag1</th>\n",
       "      <th>gyroscope_x_lag2</th>\n",
       "      <th>gyroscope_x_lag3</th>\n",
       "      <th>gyroscope_x_lag4</th>\n",
       "      <th>gyroscope_x_lag5</th>\n",
       "      <th>gyroscope_x_lag6</th>\n",
       "      <th>gyroscope_x_lag7</th>\n",
       "      <th>gyroscope_x_lag8</th>\n",
       "      <th>gyroscope_x_lag9</th>\n",
       "      <th>gyroscope_x_lag10</th>\n",
       "      <th>...</th>\n",
       "      <th>accelerometer_z_lag9</th>\n",
       "      <th>accelerometer_z_lag10</th>\n",
       "      <th>accelerometer_z_lag11</th>\n",
       "      <th>accelerometer_z_lag12</th>\n",
       "      <th>accelerometer_z_lag13</th>\n",
       "      <th>accelerometer_z_lag14</th>\n",
       "      <th>accelerometer_z_lag15</th>\n",
       "      <th>accelerometer_z_lag16</th>\n",
       "      <th>accelerometer_z_lag17</th>\n",
       "      <th>accelerometer_z_lag18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.574568</td>\n",
       "      <td>0.573335</td>\n",
       "      <td>0.569859</td>\n",
       "      <td>0.565710</td>\n",
       "      <td>0.564196</td>\n",
       "      <td>0.560832</td>\n",
       "      <td>0.560327</td>\n",
       "      <td>0.565317</td>\n",
       "      <td>0.559094</td>\n",
       "      <td>0.540087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.469817</td>\n",
       "      <td>0.474632</td>\n",
       "      <td>0.480505</td>\n",
       "      <td>0.479674</td>\n",
       "      <td>0.474859</td>\n",
       "      <td>0.477446</td>\n",
       "      <td>0.490814</td>\n",
       "      <td>0.563660</td>\n",
       "      <td>0.471328</td>\n",
       "      <td>0.219917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.573279</td>\n",
       "      <td>0.574568</td>\n",
       "      <td>0.573335</td>\n",
       "      <td>0.569859</td>\n",
       "      <td>0.565710</td>\n",
       "      <td>0.564196</td>\n",
       "      <td>0.560832</td>\n",
       "      <td>0.560327</td>\n",
       "      <td>0.565317</td>\n",
       "      <td>0.559094</td>\n",
       "      <td>...</td>\n",
       "      <td>0.467684</td>\n",
       "      <td>0.469817</td>\n",
       "      <td>0.474632</td>\n",
       "      <td>0.480505</td>\n",
       "      <td>0.479674</td>\n",
       "      <td>0.474859</td>\n",
       "      <td>0.477446</td>\n",
       "      <td>0.490814</td>\n",
       "      <td>0.563660</td>\n",
       "      <td>0.471328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.568569</td>\n",
       "      <td>0.573279</td>\n",
       "      <td>0.574568</td>\n",
       "      <td>0.573335</td>\n",
       "      <td>0.569859</td>\n",
       "      <td>0.565710</td>\n",
       "      <td>0.564196</td>\n",
       "      <td>0.560832</td>\n",
       "      <td>0.560327</td>\n",
       "      <td>0.565317</td>\n",
       "      <td>...</td>\n",
       "      <td>0.467835</td>\n",
       "      <td>0.467684</td>\n",
       "      <td>0.469817</td>\n",
       "      <td>0.474632</td>\n",
       "      <td>0.480505</td>\n",
       "      <td>0.479674</td>\n",
       "      <td>0.474859</td>\n",
       "      <td>0.477446</td>\n",
       "      <td>0.490814</td>\n",
       "      <td>0.563660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.565710</td>\n",
       "      <td>0.568569</td>\n",
       "      <td>0.573279</td>\n",
       "      <td>0.574568</td>\n",
       "      <td>0.573335</td>\n",
       "      <td>0.569859</td>\n",
       "      <td>0.565710</td>\n",
       "      <td>0.564196</td>\n",
       "      <td>0.560832</td>\n",
       "      <td>0.560327</td>\n",
       "      <td>...</td>\n",
       "      <td>0.475916</td>\n",
       "      <td>0.467835</td>\n",
       "      <td>0.467684</td>\n",
       "      <td>0.469817</td>\n",
       "      <td>0.474632</td>\n",
       "      <td>0.480505</td>\n",
       "      <td>0.479674</td>\n",
       "      <td>0.474859</td>\n",
       "      <td>0.477446</td>\n",
       "      <td>0.490814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.565429</td>\n",
       "      <td>0.565710</td>\n",
       "      <td>0.568569</td>\n",
       "      <td>0.573279</td>\n",
       "      <td>0.574568</td>\n",
       "      <td>0.573335</td>\n",
       "      <td>0.569859</td>\n",
       "      <td>0.565710</td>\n",
       "      <td>0.564196</td>\n",
       "      <td>0.560832</td>\n",
       "      <td>...</td>\n",
       "      <td>0.480618</td>\n",
       "      <td>0.475916</td>\n",
       "      <td>0.467835</td>\n",
       "      <td>0.467684</td>\n",
       "      <td>0.469817</td>\n",
       "      <td>0.474632</td>\n",
       "      <td>0.480505</td>\n",
       "      <td>0.479674</td>\n",
       "      <td>0.474859</td>\n",
       "      <td>0.477446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   gyroscope_x_lag1  gyroscope_x_lag2  gyroscope_x_lag3  gyroscope_x_lag4  \\\n",
       "0          0.574568          0.573335          0.569859          0.565710   \n",
       "1          0.573279          0.574568          0.573335          0.569859   \n",
       "2          0.568569          0.573279          0.574568          0.573335   \n",
       "3          0.565710          0.568569          0.573279          0.574568   \n",
       "4          0.565429          0.565710          0.568569          0.573279   \n",
       "\n",
       "   gyroscope_x_lag5  gyroscope_x_lag6  gyroscope_x_lag7  gyroscope_x_lag8  \\\n",
       "0          0.564196          0.560832          0.560327          0.565317   \n",
       "1          0.565710          0.564196          0.560832          0.560327   \n",
       "2          0.569859          0.565710          0.564196          0.560832   \n",
       "3          0.573335          0.569859          0.565710          0.564196   \n",
       "4          0.574568          0.573335          0.569859          0.565710   \n",
       "\n",
       "   gyroscope_x_lag9  gyroscope_x_lag10  ...  accelerometer_z_lag9  \\\n",
       "0          0.559094           0.540087  ...              0.469817   \n",
       "1          0.565317           0.559094  ...              0.467684   \n",
       "2          0.560327           0.565317  ...              0.467835   \n",
       "3          0.560832           0.560327  ...              0.475916   \n",
       "4          0.564196           0.560832  ...              0.480618   \n",
       "\n",
       "   accelerometer_z_lag10  accelerometer_z_lag11  accelerometer_z_lag12  \\\n",
       "0               0.474632               0.480505               0.479674   \n",
       "1               0.469817               0.474632               0.480505   \n",
       "2               0.467684               0.469817               0.474632   \n",
       "3               0.467835               0.467684               0.469817   \n",
       "4               0.475916               0.467835               0.467684   \n",
       "\n",
       "   accelerometer_z_lag13  accelerometer_z_lag14  accelerometer_z_lag15  \\\n",
       "0               0.474859               0.477446               0.490814   \n",
       "1               0.479674               0.474859               0.477446   \n",
       "2               0.480505               0.479674               0.474859   \n",
       "3               0.474632               0.480505               0.479674   \n",
       "4               0.469817               0.474632               0.480505   \n",
       "\n",
       "   accelerometer_z_lag16  accelerometer_z_lag17  accelerometer_z_lag18  \n",
       "0               0.563660               0.471328               0.219917  \n",
       "1               0.490814               0.563660               0.471328  \n",
       "2               0.477446               0.490814               0.563660  \n",
       "3               0.474859               0.477446               0.490814  \n",
       "4               0.479674               0.474859               0.477446  \n",
       "\n",
       "[5 rows x 108 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.X_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(dataset.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cupy 관련 지워둠 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold_1 | train_accuracy: 1.00, val_accuracy: 0.90, train_log_loss: 0.05, val_log_loss: 0.30\n",
      "fold_2 | train_accuracy: 0.99, val_accuracy: 0.92, train_log_loss: 0.05, val_log_loss: 0.23\n",
      "fold_3 | train_accuracy: 1.00, val_accuracy: 0.91, train_log_loss: 0.06, val_log_loss: 0.28\n",
      "fold_4 | train_accuracy: 1.00, val_accuracy: 0.92, train_log_loss: 0.03, val_log_loss: 0.23\n",
      "fold_5 | train_accuracy: 0.99, val_accuracy: 0.90, train_log_loss: 0.07, val_log_loss: 0.29\n",
      "mean_train_accuracy: 1.00, mean_train_loss: 0.05\n",
      "mean_val_accuracy: 0.91, mean_val_loss: 0.27\n"
     ]
    }
   ],
   "source": [
    "##### model without hyperparameter tuning\n",
    "\n",
    "# Test run 용.\n",
    "# XGboost 설명\n",
    "# XGBoost 파라미터 설명\n",
    "# sample_weights 파라미터 설명 ( final report에서는 빼기 )\n",
    "# groupKFold 설명\n",
    "# GroupShuffleSplit 설명\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GroupKFold, StratifiedGroupKFold, GridSearchCV, train_test_split, GroupShuffleSplit\n",
    "import numpy as np\n",
    "# import cupy as cp\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, log_loss, classification_report\n",
    "from sklearn.utils import class_weight\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def get_train_test_idx(dataset):\n",
    "    groups = dataset.collection_ids_df['collection_id']\n",
    "    gs = GroupShuffleSplit(n_splits=2, test_size=.2, random_state=0)\n",
    "    train_idx, test_idx = next(gs.split(dataset.X, dataset.y, groups=groups))\n",
    "    return train_idx, test_idx\n",
    "\n",
    "def train_XGBoost(dataset, xgb_params, n_splits = 5):\n",
    "    groups = dataset.collection_ids_df['collection_id']\n",
    "    gkf = GroupKFold(n_splits=n_splits)\n",
    "    xgb_clf = XGBClassifier(**xgb_params)\n",
    "\n",
    "    train_idx, _ = get_train_test_idx(dataset)\n",
    "    X_train, y_train, train_groups = dataset.X[train_idx], dataset.y[train_idx], groups[train_idx]\n",
    "\n",
    "    # if cp.cuda.runtime.getDeviceCount() > 0: # if gpu available, convert numpy array to cupy array\n",
    "    #     X_train = cp.asarray(X_train)\n",
    "\n",
    "    train_accuracy_score_list =[]\n",
    "    eval_accuracy_score_list = []\n",
    "    train_loss_score_list = []\n",
    "    eval_loss_score_list = []\n",
    "\n",
    "    fold_train_loss_value_list = []\n",
    "    fold_eval_loss_value_list = []\n",
    "\n",
    "    for i, (train_index, val_index) in enumerate(gkf.split(X_train, y_train, train_groups)):\n",
    "        X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "        y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "        eval_set =[(X_train_fold, y_train_fold), (X_val_fold, y_val_fold)]\n",
    "\n",
    "        train_class_weights = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(y_train_fold), y=y_train_fold.ravel())\n",
    "        train_sample_weights = np.array([train_class_weights[int(phase)] for phase in y_train_fold.ravel()])\n",
    "\n",
    "        xgb_clf.fit(X_train_fold, \n",
    "                    y_train_fold,\n",
    "                    eval_set=eval_set,\n",
    "                    sample_weight=train_sample_weights,\n",
    "                    verbose=False,\n",
    "                    )\n",
    "        fold_result = xgb_clf.evals_result()\n",
    "\n",
    "        train_accuracy = accuracy_score(y_train_fold, xgb_clf.predict(X_train_fold))\n",
    "        val_accuracy = accuracy_score(y_val_fold, xgb_clf.predict(X_val_fold))\n",
    "        train_log_loss = log_loss(y_train_fold, xgb_clf.predict_proba(X_train_fold))\n",
    "        val_log_loss = log_loss(y_val_fold, xgb_clf.predict_proba(X_val_fold))\n",
    "\n",
    "        print(f'fold_{i+1} | train_accuracy: {train_accuracy:.2f}, val_accuracy: {val_accuracy:.2f}, train_log_loss: {train_log_loss:.2f}, val_log_loss: {val_log_loss:.2f}')\n",
    "\n",
    "        train_accuracy_score_list.append(train_accuracy)\n",
    "        eval_accuracy_score_list.append(val_accuracy)\n",
    "        train_loss_score_list.append(train_log_loss)\n",
    "        eval_loss_score_list.append(val_log_loss)\n",
    "\n",
    "        # Store loss values for curves per fold\n",
    "        fold_train_loss_value_list.append(fold_result['validation_0']['mlogloss'])\n",
    "        fold_eval_loss_value_list.append(fold_result['validation_1']['mlogloss'])\n",
    "\n",
    "\n",
    "    print(f'mean_train_accuracy: {np.mean(train_accuracy_score_list):.2f}, mean_train_loss: {np.mean(train_loss_score_list):.2f}')\n",
    "    print(f'mean_val_accuracy: {np.mean(eval_accuracy_score_list):.2f}, mean_val_loss: {np.mean(eval_loss_score_list):.2f}')\n",
    "\n",
    "    # plot loss curve \n",
    "    plt.figure(figsize=(n_splits * 5, 5))\n",
    "    for i in range(n_splits):\n",
    "      plt.subplot(1, n_splits, i+1)\n",
    "      epochs = range(len(fold_train_loss_value_list[i]))\n",
    "      plt.plot(epochs, fold_train_loss_value_list[i], label='train_loss')\n",
    "      plt.plot(epochs, fold_eval_loss_value_list[i], label='eval_loss')\n",
    "      plt.title(f'epochs {i+1} Loss Curve')\n",
    "      plt.xlabel('epochs')\n",
    "      plt.ylabel('Log Loss')\n",
    "      plt.legend()\n",
    "      plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    return xgb_clf\n",
    "\n",
    "xgb_params={\n",
    "    'objective': 'multi:softmax',\n",
    "    'eval_metric': 'mlogloss',\n",
    "    'num_class': len(np.unique(dataset.y)),\n",
    "    'seed': 42,\n",
    "    'early_stopping_rounds': 10  # Check loss curve to decide early stopping rounds\n",
    "}\n",
    "\n",
    "if cp.cuda.runtime.getDeviceCount() > 0:\n",
    "  xgb_params['tree_method'] = 'hist'\n",
    "  xgb_params['device']= 'cuda'\n",
    "\n",
    "\n",
    "naive_model = train_XGBoost(dataset, xgb_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " heel strike       0.86      0.88      0.87        58\n",
      "   foot flat       0.94      0.98      0.96       619\n",
      "    heel off       0.97      0.91      0.94       421\n",
      "     toe off       1.00      0.99      0.99       776\n",
      "\n",
      "    accuracy                           0.97      1874\n",
      "   macro avg       0.94      0.94      0.94      1874\n",
      "weighted avg       0.97      0.97      0.97      1874\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def testXGBoost(dataset, model):\n",
    "    _, test_idx = get_train_test_idx(dataset)\n",
    "    X_test, y_test = dataset.X[test_idx], dataset.y[test_idx]\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    labels = range(len(np.unique(y_test)))\n",
    "    class_names = ['heel strike', 'foot flat', 'heel off', 'toe off']\n",
    "    print(classification_report(y_test, y_pred, labels=labels, target_names=class_names))\n",
    "\n",
    "testXGBoost(dataset, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cupy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, mean_squared_error, log_loss, classification_report\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcupy\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_train_test_idx\u001b[39m(dataset):\n\u001b[1;32m     16\u001b[0m     groups \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mcollection_ids_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcollection_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cupy'"
     ]
    }
   ],
   "source": [
    "# Final report 추가 \n",
    "# XGboost 설명   \n",
    "# XGBoost 파라미터 설명\n",
    "# sample_weights 파라미터 설명 ( final report에서는 빼기 )\n",
    "# groupKFold 설명 \n",
    "# GroupShuffleSplit 설명\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GroupKFold, StratifiedGroupKFold, GridSearchCV, train_test_split, GroupShuffleSplit\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, log_loss, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "# import cupy as cp\n",
    "\n",
    "def get_train_test_idx(dataset):\n",
    "    groups = dataset.collection_ids_df['collection_id']\n",
    "    gs = GroupShuffleSplit(n_splits=2, test_size=.2, random_state=0)\n",
    "    train_idx, test_idx = next(gs.split(dataset.X, dataset.y, groups=groups))\n",
    "\n",
    "    return train_idx, test_idx\n",
    "\n",
    "def train_XGBoost_grid_search(dataset, xgb_param_grid):\n",
    "    groups = dataset.collection_ids_df['collection_id']\n",
    "    gkf = GroupKFold(n_splits=5)\n",
    "    xgb_clf = XGBClassifier(objective='multi:softmax', \n",
    "                            eval_metric='mlogloss', \n",
    "                            device='cuda', \n",
    "                            num_class=4, \n",
    "                            seed=42)\n",
    "\n",
    "    train_idx, _ = get_train_test_idx(dataset)\n",
    "    X_train, y_train, train_groups = dataset.X[train_idx], dataset.y[train_idx], groups[train_idx]\n",
    "    \n",
    "    # if cupy.cuda.runtime.getDeviceCount() > 0: # if gpu available, convert numpy array to cupy array \n",
    "    #   X_train = cp.asarray(X_train)\n",
    "\n",
    "    xgb_grid = GridSearchCV(\n",
    "        xgb_clf,\n",
    "        param_grid=xgb_param_grid,\n",
    "        cv=gkf,\n",
    "        scoring='accuracy',\n",
    "        n_jobs=1,\n",
    "        verbose=3\n",
    "    )\n",
    "\n",
    "    grid_result = xgb_grid.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        groups=train_groups,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    print(f'best score:{grid_result.best_score_}')\n",
    "    print(f'best param:{grid_result.best_params_}')\n",
    "\n",
    "    model = grid_result.best_estimator_ \n",
    "    return model\n",
    "\n",
    "xgb_param_grid = {\n",
    "  'n_estimators': [100], # 300, 500, 700, 900], # dafault : 100\n",
    "  'learning_rate': [0.1], # 0.1, 0.5],  # default : 0.1\n",
    "  'max_depth': [6], # 7, 9], # default : 6\n",
    "  'reg_alpha': [0], # 0.1, 0.5], # default : 0\n",
    "  'reg_lambda': [1], # 0.5, 1.0], # default : 1\n",
    "  'objective': ['multi:softmax'], \n",
    "  'eval_metric': ['mlogloss'],\n",
    "  'seed': [42],\n",
    "  'num_class': [len(np.unique(dataset.y))]\n",
    "}\n",
    "\n",
    "if cp.cuda.runtime.getDeviceCount() > 0:\n",
    "  xgb_param_grid['tree_method'] = ['hist']\n",
    "  xgb_params['device']= ['cuda']\n",
    "\n",
    "model = train_XGBoost_grid_search(dataset, xgb_param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for id in dataset.collection_ids_df['collection_id'].unique():\n",
    "    mask = dataset.collection_ids_df['collection_id'].isin([id])\n",
    "    zero_mask = dataset[mask].y[dataset.y_df['target'] == 0]\n",
    "    # print(np.unique(dataset.y[mask]), np.unique(dataset.collection_ids_df[mask]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " heel strike       0.86      0.88      0.87        58\n",
      "   foot flat       0.94      0.98      0.96       619\n",
      "    heel off       0.97      0.91      0.94       421\n",
      "     toe off       1.00      0.99      0.99       776\n",
      "\n",
      "    accuracy                           0.97      1874\n",
      "   macro avg       0.94      0.94      0.94      1874\n",
      "weighted avg       0.97      0.97      0.97      1874\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import classification_report \n",
    "\n",
    "\n",
    "def test_XGBoost_grid_result(dataset, model):\n",
    "    _, test_idx = get_train_test_idx(dataset)\n",
    "    X_test, y_test = dataset.X[test_idx], dataset.y[test_idx]\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    # print(f'test accuracy: {accuracy_score(y_test, model.predict(X_test)):.2f}')  \n",
    "\n",
    "    labels = range(len(np.unique(y_test)))\n",
    "    class_names = ['heel strike', 'foot flat', 'heel off', 'toe off']\n",
    "    print(classification_report(y_test, y_pred, labels=labels, target_names=class_names))\n",
    "\n",
    "test_XGBoost_grid_result(dataset, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Grid Search with Early Stopping \n",
    "# # Final report 추가\n",
    "# # XGboost 설명\n",
    "# # XGBoost 파라미터 설명\n",
    "# # sample_weights 파라미터 설명 ( final report에서는 빼기 )\n",
    "# # groupKFold 설명 -> 하나의 그룹은 테스트 인덱스, 나머지 그룹은 \n",
    "# # GroupShuffleSplit 설명 -> \n",
    "\n",
    "# Manual로 실행한 이유 -> early stopping / sample weight을 사이킷런 grid search 모듈을 사용할 경우 설정이 어려움 \n",
    "'''\n",
    "  [TODO] Implementing Grid Search Manually\n",
    "\n",
    "  https://xgboosting.com/xgboost-early-stopping-with-grid-search/\n",
    "  https://gist.github.com/sandys/d0acf13976bae81df253d0a09436cb2b\n",
    "'''\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GroupKFold, StratifiedGroupKFold, GridSearchCV, train_test_split, GroupShuffleSplit\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, log_loss, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# import cupy as cp\n",
    "import itertools\n",
    "import time \n",
    "\n",
    "def get_train_test_idx(dataset):\n",
    "    groups = dataset.collection_ids_df['collection_id']\n",
    "    gs = GroupShuffleSplit(n_splits=2, test_size=.2, random_state=42) # 동일한 그룹에 속한 데이터는 훈련 세트와 테스트 세트에 중복되지 않도록 보장\n",
    "    train_idx, test_idx = next(gs.split(dataset.X, dataset.y, groups=groups))\n",
    "\n",
    "    return train_idx, test_idx\n",
    "\n",
    "def train_XGBoost_manual_grid_search(dataset, xgb_param_grid):\n",
    "    # n_collection_dis = len(np.unique(dataset.collection_ids))\n",
    "\n",
    "    # early stopping\n",
    "    early_stopping_rounds = 15\n",
    "\n",
    "    # train dataset\n",
    "    train_idx, _ = get_train_test_idx(dataset)\n",
    "    groups = dataset.collection_ids_df['collection_id']\n",
    "    X_train, y_train, train_groups = dataset.X[train_idx], dataset.y[train_idx], groups[train_idx]\n",
    "\n",
    "    # if cp.cuda.runtime.getDeviceCount() > 0: # if gpu available, convert numpy array to cupy array\n",
    "    #     X_train = cp.asarray(X_train) \n",
    "\n",
    "    n_splits = 10 # if the split too bit, for example 1800, toe off might not be included in the test set \n",
    "    gkf = GroupKFold(n_splits=n_splits)\n",
    "    xgb_clf = XGBClassifier()\n",
    "\n",
    "    # calculate the total rounds\n",
    "    param_values = list(xgb_param_grid.values())\n",
    "    all_combinations = list(itertools.product(*param_values))\n",
    "    total_combinations = len(all_combinations)\n",
    "    total_round = total_combinations * n_splits\n",
    "    current_round = 1\n",
    "    print(f'total round: {total_round}')\n",
    "\n",
    "    # best score \n",
    "    best_score = 0\n",
    "\n",
    "\n",
    "    for n_estimators in xgb_param_grid['n_estimators']:\n",
    "        for learning_rate in xgb_param_grid['learning_rate']:\n",
    "            for max_depth in xgb_param_grid['max_depth']:\n",
    "                for reg_alpha in xgb_param_grid['reg_alpha']:\n",
    "                    for reg_lambda in xgb_param_grid['reg_lambda']:\n",
    "                        print(f'current params: n_estimators:{n_estimators:}, learning_rate:{learning_rate}, max_depth:{max_depth}, reg_alpha:{reg_alpha}, reg_lambda:{reg_lambda}, early_stopping_rounds:{early_stopping_rounds}')\n",
    "                        \n",
    "                        start_time = time.process_time()\n",
    "\n",
    "                        train_accuracy_list = []\n",
    "                        train_log_loss_list = []\n",
    "                        val_accuracy_list = []\n",
    "                        val_log_loss_list = []\n",
    "\n",
    "                        for i, (train_index, val_index) in enumerate(gkf.split(X_train, y_train, train_groups)):\n",
    "                            X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "                            y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "                            eval_set = [(X_train_fold, y_train_fold), (X_val_fold, y_val_fold)]\n",
    "\n",
    "                            # give more weight to the minor class \n",
    "                            # train_class_weights = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(y_train_fold), y=y_train_fold.ravel())\n",
    "                            # train_sample_weights = np.array([train_class_weights[int(phase)] for phase in y_train_fold.ravel()])\n",
    "\n",
    "                            xgb_clf.set_params(\n",
    "                                n_estimators=n_estimators,\n",
    "                                learning_rate=learning_rate,\n",
    "                                max_depth=max_depth,\n",
    "                                reg_alpha=reg_alpha,\n",
    "                                reg_lambda=reg_lambda,\n",
    "                                early_stopping_rounds = early_stopping_rounds,\n",
    "                                objective=xgb_param_grid['objective'][0],\n",
    "                                eval_metric=xgb_param_grid['eval_metric'][0],\n",
    "                                seed=xgb_param_grid['seed'][0],\n",
    "                                num_class=xgb_param_grid['num_class'][0],\n",
    "                            )\n",
    "\n",
    "                            xgb_clf.fit(\n",
    "                                X_train_fold,\n",
    "                                y_train_fold,\n",
    "                                eval_set=eval_set,\n",
    "                                # sample_weight=train_sample_weights,\n",
    "                                verbose=False\n",
    "                            )\n",
    "\n",
    "                            train_accuracy = accuracy_score(y_train_fold, xgb_clf.predict(X_train_fold))\n",
    "                            val_accuracy = accuracy_score(y_val_fold, xgb_clf.predict(X_val_fold))\n",
    "                            train_log_loss = log_loss(y_train_fold, xgb_clf.predict_proba(X_train_fold))\n",
    "                            val_log_loss = log_loss(y_val_fold, xgb_clf.predict_proba(X_val_fold))\n",
    "\n",
    "                            train_accuracy_list.append(train_accuracy)\n",
    "                            val_accuracy_list.append(val_accuracy)\n",
    "                            train_log_loss_list.append(train_log_loss)\n",
    "                            val_log_loss_list.append(val_log_loss)\n",
    "\n",
    "                            end_time = time.process_time() \n",
    "\n",
    "                            print(f'{current_round}/{total_round} | Fold:{i+1}/{n_splits} | val_accuracy: {val_accuracy:.6f} | train_accuracy: {train_accuracy:.6f}, train_log_loss: {train_log_loss:.6f}, val_log_loss: {val_log_loss:.6f}, time: {(end_time - start_time):.4f}')\n",
    "                            current_round += 1\n",
    "\n",
    "                        # Compute average score across all folds\n",
    "                        average_val_accuracy = np.mean(val_accuracy_list)\n",
    "                        print(f'avg_val_accuracy: {average_val_accuracy:.6f} | avg train_accracy: {np.mean(train_accuracy):.6f}, avg_train_loss: {np.mean(train_log_loss_list):.6f}, avg_val_loss: {np.mean(val_log_loss_list):.6f}')\n",
    "                        if average_val_accuracy > best_score:\n",
    "                            best_score = average_val_accuracy\n",
    "                            best_params = {\n",
    "                                'n_estimators': n_estimators,\n",
    "                                'learning_rate': learning_rate,\n",
    "                                'max_depth': max_depth,\n",
    "                                'reg_alpha': reg_alpha,\n",
    "                                'reg_lambda': reg_lambda,\n",
    "                                'objective': xgb_param_grid['objective'],\n",
    "                                'eval_metric': xgb_param_grid['eval_metric'],\n",
    "                                'seed': xgb_param_grid['seed'],\n",
    "                                'num_class': xgb_param_grid['num_class'],\n",
    "                                'early_stopping_rounds': early_stopping_rounds\n",
    "                            }\n",
    "                            # best_result = xgb_clf.evals_result() # keep the values \n",
    "                            best_model = xgb_clf\n",
    "\n",
    "    print(f'Best Accuracy:{best_score:.6f}')\n",
    "    print(f'Best Params:\\n {best_params}')\n",
    "    return best_model\n",
    "\n",
    "xgb_param_manual_grid = {\n",
    "    'n_estimators': [100], #[100, 300, 500, 700], # dafault : 100\n",
    "    'learning_rate': [0.05], #[0.05 , 0.1, 0.5],  # default : 0.1\n",
    "    'max_depth': [10], #[4, 6, 8, 10], # default : 6\n",
    "    'reg_alpha': [0], #[0, 0.1, 0.5], # default : 0\n",
    "    'reg_lambda': [0.1], # [0.1, 0.5, 1.0], # default : 1\n",
    "    'objective': ['multi:softmax'],\n",
    "    'eval_metric': ['mlogloss'],\n",
    "    'seed': [42],\n",
    "    'num_class': [len(np.unique(dataset.y))],\n",
    "}\n",
    "\n",
    "# if cp.cuda.runtime.getDeviceCount() > 0:\n",
    "#     xgb_param_manual_grid['tree_method'] = ['hist']\n",
    "#     xgb_param_manual_grid['device'] = ['cuda']\n",
    "#     print('training running on cuda')\n",
    "\n",
    "manual_grid_model = train_XGBoost_manual_grid_search(dataset, xgb_param_manual_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "def test_XGBoost_grid_result(dataset, model):\n",
    "    _, test_idx = get_train_test_idx(dataset)\n",
    "    X_test, y_test, test_groups = dataset.X[test_idx], dataset.y[test_idx], dataset.collection_ids[test_idx]\n",
    "    print(f'test on {len(np.unique(test_groups))} collection ids:{np.unique(test_groups)}')\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f'test accuracy: {accuracy_score(y_test, model.predict(X_test)):.2f}')\n",
    "\n",
    "    labels = range(len(np.unique(y_test)))\n",
    "    class_names = ['heel strike', 'foot flat', 'heel off', 'toe off']\n",
    "    print(classification_report(y_test, y_pred, labels=labels, target_names=class_names))\n",
    "\n",
    "test_XGBoost_grid_result(dataset, manual_grid_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test-en",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
