{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# data_dir = '/content/drive/MyDrive/csv_output_with_phases'b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../csv_output_with_phases'  # Replace with your directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scikit-learn version: 1.5.2\n",
      "XGBoost version: 2.1.3\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import xgboost\n",
    "\n",
    "# To use gridsearch from sklearn for XGBoost, Scikit-learn versino should be lower than 1.6.0\n",
    "print(f\"Scikit-learn version: {sklearn.__version__}\")\n",
    "print(f\"XGBoost version: {xgboost.__version__}\")\n",
    "\n",
    "type(sklearn.__version__)\n",
    "try:\n",
    "  if sklearn.__version__ >= \"1.6.0\":\n",
    "    raise Exception(\"sklearn version should be lower than 1.6.0\")\n",
    "except Exception as e:\n",
    "  print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data head 보여주기\n",
    "# data column 설명 추가\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def load_data_from_files(data_dir):\n",
    "    all_data = []\n",
    "    for filename in os.listdir(data_dir):\n",
    "        if filename.endswith('.csv'):\n",
    "            # Extract metadata from filename\n",
    "            collection_id, step_info, _ = filename.split('_', 2)\n",
    "            step_number = ''.join(filter(str.isdigit, step_info))\n",
    "            foot = 'R' if 'R' in step_info else 'L'\n",
    "            filepath = os.path.join(data_dir, filename)\n",
    "\n",
    "            df = pd.read_csv(filepath)\n",
    "\n",
    "            df['collection_id'] = collection_id + '_' + str(step_number) + '_' + foot\n",
    "            df['filename'] = filename  # Keep track of the file\n",
    "            df['time'] = pd.to_datetime(df['time'])  # Ensure 'time' column is in datetime format\n",
    "            df['elapsed_time'] = (df['time'] - df['time'].min()).dt.total_seconds()\n",
    "            df['gyroscope_magnitude'] = np.sqrt(df['gyroscope_x']**2 + df['gyroscope_y']**2 + df['gyroscope_z']**2)\n",
    "            df['accelerometer_magnitude'] = np.sqrt(df['accelerometer_x']**2 + df['accelerometer_y']**2 + df['accelerometer_z']**2)\n",
    "            cols = ['collection_id', 'elapsed_time', 'gyroscope_x', 'gyroscope_y',\n",
    "                    'gyroscope_z', 'accelerometer_x', 'accelerometer_y', 'accelerometer_z', 'phase', 'gyroscope_magnitude', 'accelerometer_magnitude'] # , 'foot', 'filename']\n",
    "            df = df[cols]\n",
    "            # df = df[df['phase'] != 0]\n",
    "            all_data.append(df)\n",
    "    return pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "data = load_data_from_files(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>collection_id</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>gyroscope_x</th>\n",
       "      <th>gyroscope_y</th>\n",
       "      <th>gyroscope_z</th>\n",
       "      <th>accelerometer_x</th>\n",
       "      <th>accelerometer_y</th>\n",
       "      <th>accelerometer_z</th>\n",
       "      <th>phase</th>\n",
       "      <th>gyroscope_magnitude</th>\n",
       "      <th>accelerometer_magnitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vh92aaJeQLxDazem2hN5_6_L</td>\n",
       "      <td>0.000</td>\n",
       "      <td>168.63</td>\n",
       "      <td>-158.62</td>\n",
       "      <td>-113.82</td>\n",
       "      <td>-1.026752</td>\n",
       "      <td>2.276032</td>\n",
       "      <td>-8.625400</td>\n",
       "      <td>1</td>\n",
       "      <td>257.975529</td>\n",
       "      <td>8.979536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vh92aaJeQLxDazem2hN5_6_L</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-71.89</td>\n",
       "      <td>-272.58</td>\n",
       "      <td>-129.92</td>\n",
       "      <td>-2.516616</td>\n",
       "      <td>-1.586000</td>\n",
       "      <td>-2.127680</td>\n",
       "      <td>1</td>\n",
       "      <td>310.398510</td>\n",
       "      <td>3.657291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vh92aaJeQLxDazem2hN5_6_L</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-129.85</td>\n",
       "      <td>-334.53</td>\n",
       "      <td>-114.10</td>\n",
       "      <td>-0.890112</td>\n",
       "      <td>-0.234240</td>\n",
       "      <td>0.258640</td>\n",
       "      <td>1</td>\n",
       "      <td>376.550333</td>\n",
       "      <td>0.956066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vh92aaJeQLxDazem2hN5_6_L</td>\n",
       "      <td>0.015</td>\n",
       "      <td>-206.85</td>\n",
       "      <td>-334.60</td>\n",
       "      <td>-111.30</td>\n",
       "      <td>-0.842288</td>\n",
       "      <td>0.425048</td>\n",
       "      <td>-1.624064</td>\n",
       "      <td>1</td>\n",
       "      <td>408.817530</td>\n",
       "      <td>1.878217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vh92aaJeQLxDazem2hN5_6_L</td>\n",
       "      <td>0.020</td>\n",
       "      <td>-223.65</td>\n",
       "      <td>-354.62</td>\n",
       "      <td>-105.70</td>\n",
       "      <td>0.108824</td>\n",
       "      <td>0.293288</td>\n",
       "      <td>-1.969568</td>\n",
       "      <td>1</td>\n",
       "      <td>432.373862</td>\n",
       "      <td>1.994256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              collection_id  elapsed_time  gyroscope_x  gyroscope_y  \\\n",
       "0  vh92aaJeQLxDazem2hN5_6_L         0.000       168.63      -158.62   \n",
       "1  vh92aaJeQLxDazem2hN5_6_L         0.005       -71.89      -272.58   \n",
       "2  vh92aaJeQLxDazem2hN5_6_L         0.010      -129.85      -334.53   \n",
       "3  vh92aaJeQLxDazem2hN5_6_L         0.015      -206.85      -334.60   \n",
       "4  vh92aaJeQLxDazem2hN5_6_L         0.020      -223.65      -354.62   \n",
       "\n",
       "   gyroscope_z  accelerometer_x  accelerometer_y  accelerometer_z  phase  \\\n",
       "0      -113.82        -1.026752         2.276032        -8.625400      1   \n",
       "1      -129.92        -2.516616        -1.586000        -2.127680      1   \n",
       "2      -114.10        -0.890112        -0.234240         0.258640      1   \n",
       "3      -111.30        -0.842288         0.425048        -1.624064      1   \n",
       "4      -105.70         0.108824         0.293288        -1.969568      1   \n",
       "\n",
       "   gyroscope_magnitude  accelerometer_magnitude  \n",
       "0           257.975529                 8.979536  \n",
       "1           310.398510                 3.657291  \n",
       "2           376.550333                 0.956066  \n",
       "3           408.817530                 1.878217  \n",
       "4           432.373862                 1.994256  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "\n",
    "def preprocess_data(data):\n",
    "    # Define features and target\n",
    "    features = ['gyroscope_x', 'gyroscope_y', 'gyroscope_z',\n",
    "                'accelerometer_x', 'accelerometer_y', 'accelerometer_z', 'gyroscope_magnitude', 'accelerometer_magnitude']\n",
    "    target = 'phase'\n",
    "\n",
    "    # Drop rows with missing values\n",
    "    data = data.dropna(subset=features + [target])\n",
    "\n",
    "    # Drop rows with no event\n",
    "    data = data[data[target] != 0]\n",
    "\n",
    "    # Subtract the phase by 1 : XGboost takes a value from 0 ~ (num_class-1)\n",
    "    data[target] = data[target] - 1\n",
    "\n",
    "    # Normalize features\n",
    "    scaler = MinMaxScaler()\n",
    "    data.loc[:, features] = scaler.fit_transform(data[features])\n",
    "\n",
    "    # Encode target labels\n",
    "    label_encoder = LabelEncoder()\n",
    "    data.loc[:, target] = label_encoder.fit_transform(data[target])\n",
    "\n",
    "    return data, label_encoder\n",
    "\n",
    "scaled_data, label_encoder = preprocess_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>collection_id</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>gyroscope_x</th>\n",
       "      <th>gyroscope_y</th>\n",
       "      <th>gyroscope_z</th>\n",
       "      <th>accelerometer_x</th>\n",
       "      <th>accelerometer_y</th>\n",
       "      <th>accelerometer_z</th>\n",
       "      <th>phase</th>\n",
       "      <th>gyroscope_magnitude</th>\n",
       "      <th>accelerometer_magnitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vh92aaJeQLxDazem2hN5_6_L</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.691635</td>\n",
       "      <td>0.489820</td>\n",
       "      <td>0.233674</td>\n",
       "      <td>0.414113</td>\n",
       "      <td>0.588787</td>\n",
       "      <td>0.219917</td>\n",
       "      <td>0</td>\n",
       "      <td>0.242176</td>\n",
       "      <td>0.560265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vh92aaJeQLxDazem2hN5_6_L</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.498991</td>\n",
       "      <td>0.405266</td>\n",
       "      <td>0.212696</td>\n",
       "      <td>0.335429</td>\n",
       "      <td>0.371178</td>\n",
       "      <td>0.471328</td>\n",
       "      <td>0</td>\n",
       "      <td>0.291461</td>\n",
       "      <td>0.220911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vh92aaJeQLxDazem2hN5_6_L</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.452568</td>\n",
       "      <td>0.359302</td>\n",
       "      <td>0.233309</td>\n",
       "      <td>0.421329</td>\n",
       "      <td>0.447344</td>\n",
       "      <td>0.563660</td>\n",
       "      <td>0</td>\n",
       "      <td>0.353653</td>\n",
       "      <td>0.048677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vh92aaJeQLxDazem2hN5_6_L</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.390895</td>\n",
       "      <td>0.359250</td>\n",
       "      <td>0.236957</td>\n",
       "      <td>0.423855</td>\n",
       "      <td>0.484492</td>\n",
       "      <td>0.490814</td>\n",
       "      <td>0</td>\n",
       "      <td>0.383989</td>\n",
       "      <td>0.107475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vh92aaJeQLxDazem2hN5_6_L</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.377439</td>\n",
       "      <td>0.344396</td>\n",
       "      <td>0.244254</td>\n",
       "      <td>0.474086</td>\n",
       "      <td>0.477068</td>\n",
       "      <td>0.477446</td>\n",
       "      <td>0</td>\n",
       "      <td>0.406135</td>\n",
       "      <td>0.114874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              collection_id  elapsed_time  gyroscope_x  gyroscope_y  \\\n",
       "0  vh92aaJeQLxDazem2hN5_6_L         0.000     0.691635     0.489820   \n",
       "1  vh92aaJeQLxDazem2hN5_6_L         0.005     0.498991     0.405266   \n",
       "2  vh92aaJeQLxDazem2hN5_6_L         0.010     0.452568     0.359302   \n",
       "3  vh92aaJeQLxDazem2hN5_6_L         0.015     0.390895     0.359250   \n",
       "4  vh92aaJeQLxDazem2hN5_6_L         0.020     0.377439     0.344396   \n",
       "\n",
       "   gyroscope_z  accelerometer_x  accelerometer_y  accelerometer_z  phase  \\\n",
       "0     0.233674         0.414113         0.588787         0.219917      0   \n",
       "1     0.212696         0.335429         0.371178         0.471328      0   \n",
       "2     0.233309         0.421329         0.447344         0.563660      0   \n",
       "3     0.236957         0.423855         0.484492         0.490814      0   \n",
       "4     0.244254         0.474086         0.477068         0.477446      0   \n",
       "\n",
       "   gyroscope_magnitude  accelerometer_magnitude  \n",
       "0             0.242176                 0.560265  \n",
       "1             0.291461                 0.220911  \n",
       "2             0.353653                 0.048677  \n",
       "3             0.383989                 0.107475  \n",
       "4             0.406135                 0.114874  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the lag size (ACF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average lag_size: 19\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.stattools import acf\n",
    "from joblib import Parallel, delayed\n",
    "import numpy as np\n",
    "\n",
    "def compute_cutoff_lag(target, nlags=50):\n",
    "    \"\"\"Compute cutoff lag for a single time series.\"\"\"\n",
    "    acf_values, confint = acf(target, alpha=0.05, nlags=nlags)\n",
    "    # confidential interval\n",
    "    lower_bound = confint[1:, 0] - acf_values[1:]\n",
    "    upper_bound = confint[1:, 1] - acf_values[1:]\n",
    "    cutoff_lag = np.where((acf_values[1:] < lower_bound) | (acf_values[1:] > upper_bound))[0]\n",
    "    if len(cutoff_lag) > 0:\n",
    "        return cutoff_lag[-1] + 1  # Adjust index to match lag\n",
    "    return 0\n",
    "\n",
    "def get_lag_size(data, nlags=50):\n",
    "    \"\"\"Compute average cutoff lag across all collection IDs.\"\"\"\n",
    "    collection_ids = data['collection_id'].unique()\n",
    "\n",
    "    # Use parallel processing for speed\n",
    "    cutoff_lags = Parallel(n_jobs=-1)(delayed(compute_cutoff_lag)(\n",
    "        data[data['collection_id'] == collection_id]['phase'], nlags\n",
    "    ) for collection_id in collection_ids)\n",
    "\n",
    "    lag_size = round(np.mean(cutoff_lags))\n",
    "    print(f'average lag_size: {lag_size}')\n",
    "    return lag_size\n",
    "\n",
    "lag_size = get_lag_size(scaled_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example and explanation**  \n",
    "- ACF measures the temporal correlation of the target values.  \n",
    "- The blue region shows the 95% confidence interval of the correlation of the target values, thus the points that are outside of the blue region are statistically significant.    \n",
    "- The cut-off point is where the ACF curve crosses the blue line, and the lag at which the ACF curve crosses the blue line is the optimal lag.   \n",
    "- So the lag size is determined by averaging the lags at which the ACF curve crosses the blue line across all collection IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scaled_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m     plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mACF Plot for Collection ID: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrandom_collection_id[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     12\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m---> 14\u001b[0m plot_acf_example(\u001b[43mscaled_data\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'scaled_data' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "\n",
    "# ACF example plot for one random collection id\n",
    "def plot_acf_example(data):\n",
    "    random_collection_id = np.random.choice(data['collection_id'].unique(), 1, replace=False)\n",
    "    phase = data[data['collection_id'] == random_collection_id[0]]['phase']\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plot_acf(phase, lags=50)\n",
    "    plt.title(f'ACF Plot for Collection ID: {random_collection_id[0]}')\n",
    "    plt.xlabel('Lag')\n",
    "    plt.ylabel('Autocorrelation')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "plot_acf_example(scaled_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lagged Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lagged_DataSet():\n",
    "    def __init__(self, data, features, target, lag_size=30):\n",
    "        self.data = data\n",
    "        self.features = features\n",
    "        self.len_features = len(self.features)\n",
    "        self.target = target\n",
    "        self.lag_size = lag_size\n",
    "\n",
    "        self.collection_id = 0\n",
    "\n",
    "        self.X = pd.DataFrame()\n",
    "        self.y = pd.DataFrame()\n",
    "        self.collection_ids = pd.DataFrame()\n",
    "\n",
    "        for collection_id in self.data['collection_id'].unique()[:50]:\n",
    "            collection_data = self.data[self.data['collection_id'] == collection_id].sort_values(by='elapsed_time')\n",
    "            collection_data = collection_data[self.features + ['phase'] + ['collection_id']]\n",
    "            # collection_data = collection_data[self.features + ['phase']]\n",
    "            collection_length = len(collection_data)\n",
    "            if collection_length > self.lag_size:\n",
    "                lagged_features = {}\n",
    "                for j in range(self.len_features):\n",
    "                    for i in range(1, self.lag_size):\n",
    "                        lagged_features[f'{self.features[j]}_lag{i}'] = collection_data[self.features[j]].shift(i)\n",
    "                lagged_df = pd.DataFrame(lagged_features)\n",
    "                collection_data = pd.concat([collection_data, lagged_df], axis=1)\n",
    "\n",
    "            collection_data.dropna(inplace=True)\n",
    "            collection_data['collection_id'] = self.collection_id\n",
    "\n",
    "            collection_data = collection_data.drop(columns=self.features)\n",
    "            collection_data = collection_data.dropna(axis=1, how='any')\n",
    "\n",
    "            # self.X = pd.concat([self.X, collection_data.drop(columns=[self.target])], ignore_index=True)\n",
    "            self.X = pd.concat([self.X, collection_data.drop(columns=['phase', 'collection_id'])], ignore_index=True)\n",
    "            self.y = pd.concat([self.y, collection_data[[self.target]]], ignore_index=True)\n",
    "            self.collection_ids = pd.concat([self.collection_ids, collection_data[['collection_id']]], ignore_index=True)\n",
    "\n",
    "            self.collection_id += 1\n",
    "\n",
    "        self.X_df = self.X.copy()\n",
    "        self.y_df = self.y.copy()\n",
    "        self.collection_ids_df = self.collection_ids.copy()\n",
    "\n",
    "        self.X = self.X_df.values\n",
    "        self.y = self.y_df.values\n",
    "        self.collection_ids = self.collection_ids_df.values \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "features = ['gyroscope_x', 'gyroscope_y', 'gyroscope_z',\n",
    "            'accelerometer_x', 'accelerometer_y', 'accelerometer_z']\n",
    "target = 'phase'\n",
    "dataset = Lagged_DataSet(scaled_data, features, target, lag_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gyroscope_x_lag1</th>\n",
       "      <th>gyroscope_x_lag2</th>\n",
       "      <th>gyroscope_x_lag3</th>\n",
       "      <th>gyroscope_x_lag4</th>\n",
       "      <th>gyroscope_x_lag5</th>\n",
       "      <th>gyroscope_x_lag6</th>\n",
       "      <th>gyroscope_x_lag7</th>\n",
       "      <th>gyroscope_x_lag8</th>\n",
       "      <th>gyroscope_x_lag9</th>\n",
       "      <th>gyroscope_x_lag10</th>\n",
       "      <th>...</th>\n",
       "      <th>accelerometer_z_lag9</th>\n",
       "      <th>accelerometer_z_lag10</th>\n",
       "      <th>accelerometer_z_lag11</th>\n",
       "      <th>accelerometer_z_lag12</th>\n",
       "      <th>accelerometer_z_lag13</th>\n",
       "      <th>accelerometer_z_lag14</th>\n",
       "      <th>accelerometer_z_lag15</th>\n",
       "      <th>accelerometer_z_lag16</th>\n",
       "      <th>accelerometer_z_lag17</th>\n",
       "      <th>accelerometer_z_lag18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.574568</td>\n",
       "      <td>0.573335</td>\n",
       "      <td>0.569859</td>\n",
       "      <td>0.565710</td>\n",
       "      <td>0.564196</td>\n",
       "      <td>0.560832</td>\n",
       "      <td>0.560327</td>\n",
       "      <td>0.565317</td>\n",
       "      <td>0.559094</td>\n",
       "      <td>0.540087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.469817</td>\n",
       "      <td>0.474632</td>\n",
       "      <td>0.480505</td>\n",
       "      <td>0.479674</td>\n",
       "      <td>0.474859</td>\n",
       "      <td>0.477446</td>\n",
       "      <td>0.490814</td>\n",
       "      <td>0.563660</td>\n",
       "      <td>0.471328</td>\n",
       "      <td>0.219917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.573279</td>\n",
       "      <td>0.574568</td>\n",
       "      <td>0.573335</td>\n",
       "      <td>0.569859</td>\n",
       "      <td>0.565710</td>\n",
       "      <td>0.564196</td>\n",
       "      <td>0.560832</td>\n",
       "      <td>0.560327</td>\n",
       "      <td>0.565317</td>\n",
       "      <td>0.559094</td>\n",
       "      <td>...</td>\n",
       "      <td>0.467684</td>\n",
       "      <td>0.469817</td>\n",
       "      <td>0.474632</td>\n",
       "      <td>0.480505</td>\n",
       "      <td>0.479674</td>\n",
       "      <td>0.474859</td>\n",
       "      <td>0.477446</td>\n",
       "      <td>0.490814</td>\n",
       "      <td>0.563660</td>\n",
       "      <td>0.471328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.568569</td>\n",
       "      <td>0.573279</td>\n",
       "      <td>0.574568</td>\n",
       "      <td>0.573335</td>\n",
       "      <td>0.569859</td>\n",
       "      <td>0.565710</td>\n",
       "      <td>0.564196</td>\n",
       "      <td>0.560832</td>\n",
       "      <td>0.560327</td>\n",
       "      <td>0.565317</td>\n",
       "      <td>...</td>\n",
       "      <td>0.467835</td>\n",
       "      <td>0.467684</td>\n",
       "      <td>0.469817</td>\n",
       "      <td>0.474632</td>\n",
       "      <td>0.480505</td>\n",
       "      <td>0.479674</td>\n",
       "      <td>0.474859</td>\n",
       "      <td>0.477446</td>\n",
       "      <td>0.490814</td>\n",
       "      <td>0.563660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.565710</td>\n",
       "      <td>0.568569</td>\n",
       "      <td>0.573279</td>\n",
       "      <td>0.574568</td>\n",
       "      <td>0.573335</td>\n",
       "      <td>0.569859</td>\n",
       "      <td>0.565710</td>\n",
       "      <td>0.564196</td>\n",
       "      <td>0.560832</td>\n",
       "      <td>0.560327</td>\n",
       "      <td>...</td>\n",
       "      <td>0.475916</td>\n",
       "      <td>0.467835</td>\n",
       "      <td>0.467684</td>\n",
       "      <td>0.469817</td>\n",
       "      <td>0.474632</td>\n",
       "      <td>0.480505</td>\n",
       "      <td>0.479674</td>\n",
       "      <td>0.474859</td>\n",
       "      <td>0.477446</td>\n",
       "      <td>0.490814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.565429</td>\n",
       "      <td>0.565710</td>\n",
       "      <td>0.568569</td>\n",
       "      <td>0.573279</td>\n",
       "      <td>0.574568</td>\n",
       "      <td>0.573335</td>\n",
       "      <td>0.569859</td>\n",
       "      <td>0.565710</td>\n",
       "      <td>0.564196</td>\n",
       "      <td>0.560832</td>\n",
       "      <td>...</td>\n",
       "      <td>0.480618</td>\n",
       "      <td>0.475916</td>\n",
       "      <td>0.467835</td>\n",
       "      <td>0.467684</td>\n",
       "      <td>0.469817</td>\n",
       "      <td>0.474632</td>\n",
       "      <td>0.480505</td>\n",
       "      <td>0.479674</td>\n",
       "      <td>0.474859</td>\n",
       "      <td>0.477446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   gyroscope_x_lag1  gyroscope_x_lag2  gyroscope_x_lag3  gyroscope_x_lag4  \\\n",
       "0          0.574568          0.573335          0.569859          0.565710   \n",
       "1          0.573279          0.574568          0.573335          0.569859   \n",
       "2          0.568569          0.573279          0.574568          0.573335   \n",
       "3          0.565710          0.568569          0.573279          0.574568   \n",
       "4          0.565429          0.565710          0.568569          0.573279   \n",
       "\n",
       "   gyroscope_x_lag5  gyroscope_x_lag6  gyroscope_x_lag7  gyroscope_x_lag8  \\\n",
       "0          0.564196          0.560832          0.560327          0.565317   \n",
       "1          0.565710          0.564196          0.560832          0.560327   \n",
       "2          0.569859          0.565710          0.564196          0.560832   \n",
       "3          0.573335          0.569859          0.565710          0.564196   \n",
       "4          0.574568          0.573335          0.569859          0.565710   \n",
       "\n",
       "   gyroscope_x_lag9  gyroscope_x_lag10  ...  accelerometer_z_lag9  \\\n",
       "0          0.559094           0.540087  ...              0.469817   \n",
       "1          0.565317           0.559094  ...              0.467684   \n",
       "2          0.560327           0.565317  ...              0.467835   \n",
       "3          0.560832           0.560327  ...              0.475916   \n",
       "4          0.564196           0.560832  ...              0.480618   \n",
       "\n",
       "   accelerometer_z_lag10  accelerometer_z_lag11  accelerometer_z_lag12  \\\n",
       "0               0.474632               0.480505               0.479674   \n",
       "1               0.469817               0.474632               0.480505   \n",
       "2               0.467684               0.469817               0.474632   \n",
       "3               0.467835               0.467684               0.469817   \n",
       "4               0.475916               0.467835               0.467684   \n",
       "\n",
       "   accelerometer_z_lag13  accelerometer_z_lag14  accelerometer_z_lag15  \\\n",
       "0               0.474859               0.477446               0.490814   \n",
       "1               0.479674               0.474859               0.477446   \n",
       "2               0.480505               0.479674               0.474859   \n",
       "3               0.474632               0.480505               0.479674   \n",
       "4               0.469817               0.474632               0.480505   \n",
       "\n",
       "   accelerometer_z_lag16  accelerometer_z_lag17  accelerometer_z_lag18  \n",
       "0               0.563660               0.471328               0.219917  \n",
       "1               0.490814               0.563660               0.471328  \n",
       "2               0.477446               0.490814               0.563660  \n",
       "3               0.474859               0.477446               0.490814  \n",
       "4               0.479674               0.474859               0.477446  \n",
       "\n",
       "[5 rows x 108 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.X_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(dataset.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune parameters and train the XGBoost model \n",
    "XGBoost was desinged to be used with large complicated datas sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Grid Search with Early Stopping\n",
    "# # Final report 추가\n",
    "# # XGboost 설명\n",
    "# # XGBoost 파라미터 설명\n",
    "# # sample_weights 파라미터 설명 ( final report에서는 빼기 )\n",
    "# # groupKFold 설명 -> 하나의 그룹은 테스트 인덱스, 나머지 그룹은\n",
    "# # GroupShuffleSplit 설명 ->\n",
    "\n",
    "# Manual로 실행한 이유 -> early stopping / sample weight을 사이킷런 grid search 모듈을 사용할 경우 설정이 어려움\n",
    "'''\n",
    "  [TODO] Implementing Grid Search Manually\n",
    "\n",
    "  https://xgboosting.com/xgboost-early-stopping-with-grid-search/\n",
    "  https://gist.github.com/sandys/d0acf13976bae81df253d0a09436cb2b\n",
    "'''\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GroupKFold, StratifiedGroupKFold, GridSearchCV, train_test_split, GroupShuffleSplit\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, log_loss, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cupy as cp\n",
    "import itertools\n",
    "import time\n",
    "\n",
    "def get_train_test_idx(dataset):\n",
    "    '''\n",
    "    This function splits the dataset into training and testing sets using GroupShuffleSplit.\n",
    "    It ensures that the data are set based on groups randomly, and the same groups are not split between training and testing sets.\n",
    "    '''\n",
    "    groups = dataset.collection_ids_df['collection_id']\n",
    "    gs = GroupShuffleSplit(n_splits=2, test_size=.2, random_state=42) # 동일한 그룹에 속한 데이터는 훈련 세트와 테스트 세트에 중복되지 않도록 보장\n",
    "    train_idx, test_idx = next(gs.split(dataset.X, dataset.y, groups=groups))\n",
    "\n",
    "    return train_idx, test_idx\n",
    "\n",
    "\n",
    "def train_XGBoost_manual_grid_search(dataset, xgb_param_grid):\n",
    "    '''\n",
    "    This function trains the XGBoost model using the given parameters.\n",
    "    It performs cross-validation with GroupKFold and early stopping.\n",
    "    GroupKFold is used to ensure that the same groups are not split between training and validation sets per each fold.\n",
    "    '''\n",
    "\n",
    "    # early stopping\n",
    "    early_stopping_rounds = 15\n",
    "\n",
    "    # train dataset\n",
    "    train_idx, _ = get_train_test_idx(dataset)\n",
    "    groups = dataset.collection_ids_df['collection_id']\n",
    "    X_train, y_train, train_groups = dataset.X[train_idx], dataset.y[train_idx], groups[train_idx]\n",
    "\n",
    "    if cp.cuda.runtime.getDeviceCount() > 0: # if gpu available, convert numpy array to cupy array\n",
    "        X_train = cp.asarray(X_train)\n",
    "\n",
    "    n_splits = 10 # if the split too bit, for example 1800, toe off might not be included in the test set\n",
    "    gkf = GroupKFold(n_splits=n_splits)\n",
    "    xgb_clf = XGBClassifier()\n",
    "\n",
    "    # calculate the total rounds\n",
    "    param_values = list(xgb_param_grid.values())\n",
    "    all_combinations = list(itertools.product(*param_values))\n",
    "    total_combinations = len(all_combinations)\n",
    "    total_round = total_combinations * n_splits\n",
    "    current_round = 1\n",
    "    print(f'total round: {total_round}')\n",
    "\n",
    "    # best score\n",
    "    best_score = 0\n",
    "    best_params = {}\n",
    "    best_eval_result = None\n",
    "    best_model = None\n",
    "\n",
    "\n",
    "    for n_estimators in xgb_param_grid['n_estimators']:\n",
    "        for learning_rate in xgb_param_grid['learning_rate']:\n",
    "            for max_depth in xgb_param_grid['max_depth']:\n",
    "                for reg_alpha in xgb_param_grid['reg_alpha']:\n",
    "                    for reg_lambda in xgb_param_grid['reg_lambda']:\n",
    "                        print(f'current params: n_estimators:{n_estimators:}, learning_rate:{learning_rate}, max_depth:{max_depth}, reg_alpha:{reg_alpha}, reg_lambda:{reg_lambda}, early_stopping_rounds:{early_stopping_rounds}')\n",
    "\n",
    "                        start_time = time.process_time()\n",
    "\n",
    "                        # store result values per fold\n",
    "                        train_accuracy_list = []\n",
    "                        train_log_loss_list = []\n",
    "                        val_accuracy_list = []\n",
    "                        val_log_loss_list = []\n",
    "\n",
    "                        # values for loss_curve\n",
    "                        fold_train_loss_value_list = []\n",
    "                        fold_eval_loss_value_list = []\n",
    "\n",
    "                        for i, (train_index, val_index) in enumerate(gkf.split(X_train, y_train, train_groups)):\n",
    "                            X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "                            y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "                            eval_set = [(X_train_fold, y_train_fold), (X_val_fold, y_val_fold)]\n",
    "\n",
    "                            # give more weight to the minor class\n",
    "                            # train_class_weights = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(y_train_fold), y=y_train_fold.ravel())\n",
    "                            # train_sample_weights = np.array([train_class_weights[int(phase)] for phase in y_train_fold.ravel()])\n",
    "\n",
    "                            xgb_clf.set_params(\n",
    "                                n_estimators=n_estimators,\n",
    "                                learning_rate=learning_rate,\n",
    "                                max_depth=max_depth,\n",
    "                                reg_alpha=reg_alpha,\n",
    "                                reg_lambda=reg_lambda,\n",
    "                                early_stopping_rounds = early_stopping_rounds,\n",
    "                                objective=xgb_param_grid['objective'][0],\n",
    "                                eval_metric=xgb_param_grid['eval_metric'][0],\n",
    "                                seed=xgb_param_grid['seed'][0],\n",
    "                                num_class=xgb_param_grid['num_class'][0],\n",
    "                            )\n",
    "\n",
    "                            xgb_clf.fit(\n",
    "                                X_train_fold,\n",
    "                                y_train_fold,\n",
    "                                eval_set=eval_set,\n",
    "                                # sample_weight=train_sample_weights,\n",
    "                                verbose=False\n",
    "                            )\n",
    "\n",
    "                            fold_result = xgb_clf.evals_result()\n",
    "\n",
    "                            train_accuracy = accuracy_score(y_train_fold, xgb_clf.predict(X_train_fold))\n",
    "                            val_accuracy = accuracy_score(y_val_fold, xgb_clf.predict(X_val_fold))\n",
    "                            train_log_loss = log_loss(y_train_fold, xgb_clf.predict_proba(X_train_fold))\n",
    "                            val_log_loss = log_loss(y_val_fold, xgb_clf.predict_proba(X_val_fold))\n",
    "\n",
    "                            train_accuracy_list.append(train_accuracy)\n",
    "                            val_accuracy_list.append(val_accuracy)\n",
    "                            train_log_loss_list.append(train_log_loss)\n",
    "                            val_log_loss_list.append(val_log_loss)\n",
    "\n",
    "                            fold_train_loss_value_list.append(fold_result['validation_0']['mlogloss']) # training loss values\n",
    "                            fold_eval_loss_value_list.append(fold_result['validation_1']['mlogloss']) # eval loss values\n",
    "\n",
    "                            end_time = time.process_time()\n",
    "\n",
    "                            print(f'{current_round}/{total_round} | Fold:{i+1}/{n_splits} | val_accuracy: {val_accuracy:.6f} | train_accuracy: {train_accuracy:.6f}, train_log_loss: {train_log_loss:.6f}, val_log_loss: {val_log_loss:.6f}, time: {(end_time - start_time):.4f}')\n",
    "                            current_round += 1\n",
    "\n",
    "                        # Compute average score across all folds\n",
    "                        average_val_accuracy = np.mean(val_accuracy_list)\n",
    "                        print(f'avg_val_accuracy: {average_val_accuracy:.6f} | avg train_accracy: {np.mean(train_accuracy):.6f}, avg_train_loss: {np.mean(train_log_loss_list):.6f}, avg_val_loss: {np.mean(val_log_loss_list):.6f}')\n",
    "                        if average_val_accuracy > best_score:\n",
    "                            best_score = average_val_accuracy\n",
    "                            best_params = {\n",
    "                                'n_estimators': n_estimators,\n",
    "                                'learning_rate': learning_rate,\n",
    "                                'max_depth': max_depth,\n",
    "                                'reg_alpha': reg_alpha,\n",
    "                                'reg_lambda': reg_lambda,\n",
    "                                'objective': xgb_param_grid['objective'],\n",
    "                                'eval_metric': xgb_param_grid['eval_metric'],\n",
    "                                'seed': xgb_param_grid['seed'],\n",
    "                                'num_class': xgb_param_grid['num_class'],\n",
    "                                'early_stopping_rounds': early_stopping_rounds\n",
    "                            }\n",
    "                            best_eval_result = {'validation_0': fold_train_loss_value_list, 'validation_1': fold_eval_loss_value_list}\n",
    "                            best_model = xgb_clf\n",
    "\n",
    "\n",
    "    print(f'Best Accuracy:{best_score:.6f}')\n",
    "    print(f'Best Params:\\n {best_params}')\n",
    "    return best_model, best_params, best_eval_result\n",
    "\n",
    "xgb_param_manual_grid = {\n",
    "    'n_estimators': [100], #[100, 300, 500, 700], # dafault : 100\n",
    "    'learning_rate': [0.05], #[0.05 , 0.1, 0.5],  # default : 0.1\n",
    "    'max_depth': [10], #[4, 6, 8, 10], # default : 6\n",
    "    'reg_alpha': [0], #[0, 0.1, 0.5], # default : 0\n",
    "    'reg_lambda': [0.1], # [0.1, 0.5, 1.0], # default : 1\n",
    "    'objective': ['multi:softmax'],\n",
    "    'eval_metric': ['mlogloss'],\n",
    "    'seed': [42],\n",
    "    'num_class': [len(np.unique(dataset.y))],\n",
    "}\n",
    "\n",
    "if cp.cuda.runtime.getDeviceCount() > 0:\n",
    "    xgb_param_manual_grid['tree_method'] = ['hist']\n",
    "    xgb_param_manual_grid['device'] = ['cuda']\n",
    "    print('training running on cuda')\n",
    "\n",
    "manual_grid_model, best_params, best_eval_result = train_XGBoost_manual_grid_search(dataset, xgb_param_manual_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "def test_XGBoost_grid_result(dataset, model):\n",
    "    _, test_idx = get_train_test_idx(dataset)\n",
    "    X_test, y_test, test_groups = dataset.X[test_idx], dataset.y[test_idx], dataset.collection_ids[test_idx]\n",
    "    print(f'test on {len(np.unique(test_groups))} collection ids:{np.unique(test_groups)}')\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f'test accuracy: {accuracy_score(y_test, model.predict(X_test)):.2f}')\n",
    "\n",
    "    labels = range(len(np.unique(y_test)))\n",
    "    class_names = ['heel strike', 'foot flat', 'heel off', 'toe off']\n",
    "    print(classification_report(y_test, y_pred, labels=labels, target_names=class_names))\n",
    "\n",
    "test_XGBoost_grid_result(dataset, manual_grid_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test-en",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
